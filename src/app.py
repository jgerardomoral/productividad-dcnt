"""
Dashboard de Productividad del Doctorado en Ciencias de la Nutrici√≥n Traslacional
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
from pathlib import Path
import networkx as nx
from collections import Counter
from config_context import (
    EPIDEMIOLOGIA_MEXICO,
    EPIDEMIOLOGIA_JALISCO,
    ODS_CONTEXTO,
    PRONACES_CONTEXTO,
    LINEAS_INVESTIGACION,
    REGION_OCCIDENTE,
    INFRAESTRUCTURA_UDG,
    INVESTIGACION_TRASLACIONAL
)

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Dashboard Productividad DCNT",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Inicializar el estado del tema
if 'theme' not in st.session_state:
    st.session_state.theme = 'light'

# Funci√≥n para obtener estilos CSS seg√∫n el tema
def get_theme_css(theme):
    if theme == 'dark':
        return """
        <style>
            /* =========================== TEMA OSCURO =========================== */

            /* Fondo principal de la app */
            .stApp {
                background-color: #0e1117 !important;
            }

            /* Fondo del contenido principal */
            .main .block-container {
                background-color: #0e1117 !important;
            }

            /* Sidebar */
            [data-testid="stSidebar"] {
                background-color: #262730 !important;
            }

            [data-testid="stSidebar"] * {
                color: #fafafa !important;
            }

            /* Headers personalizados */
            .main-header {
                font-size: 2.5rem;
                font-weight: bold;
                color: #58a6ff !important;
                text-align: center;
                padding: 1rem 0;
            }

            .section-header {
                font-size: 1.8rem;
                font-weight: bold;
                color: #e6edf3 !important;
                border-bottom: 3px solid #58a6ff;
                padding-bottom: 0.5rem;
                margin-top: 2rem;
            }

            /* Texto general */
            .stMarkdown, p, span, label, div {
                color: #c9d1d9 !important;
            }

            h1, h2, h3, h4, h5, h6 {
                color: #e6edf3 !important;
            }

            /* M√©tricas */
            [data-testid="stMetric"] {
                background-color: #161b22 !important;
                padding: 1rem;
                border-radius: 8px;
                border: 1px solid #30363d;
            }

            [data-testid="stMetricValue"] {
                color: #58a6ff !important;
            }

            [data-testid="stMetricLabel"] {
                color: #8b949e !important;
            }

            /* Tabs */
            .stTabs [data-baseweb="tab-list"] {
                background-color: #161b22 !important;
            }

            .stTabs [data-baseweb="tab"] {
                color: #8b949e !important;
                background-color: #0d1117 !important;
            }

            .stTabs [aria-selected="true"] {
                color: #58a6ff !important;
                background-color: #161b22 !important;
                border-bottom-color: #58a6ff !important;
            }

            /* Radio buttons */
            [data-testid="stRadio"] label {
                color: #c9d1d9 !important;
            }

            /* Dividers */
            hr {
                border-color: #30363d !important;
            }

            /* Success/Info boxes */
            .stAlert {
                background-color: #161b22 !important;
                color: #c9d1d9 !important;
                border: 1px solid #30363d;
            }
        </style>
        """
    else:
        return """
        <style>
            /* =========================== TEMA CLARO =========================== */

            /* Fondo principal de la app */
            .stApp {
                background-color: #ffffff !important;
            }

            /* Fondo del contenido principal */
            .main .block-container {
                background-color: #ffffff !important;
            }

            /* Sidebar */
            [data-testid="stSidebar"] {
                background-color: #f0f2f6 !important;
            }

            [data-testid="stSidebar"] * {
                color: #31333F !important;
            }

            /* Headers personalizados */
            .main-header {
                font-size: 2.5rem;
                font-weight: bold;
                color: #1f77b4 !important;
                text-align: center;
                padding: 1rem 0;
            }

            .section-header {
                font-size: 1.8rem;
                font-weight: bold;
                color: #2c3e50 !important;
                border-bottom: 3px solid #1f77b4;
                padding-bottom: 0.5rem;
                margin-top: 2rem;
            }

            /* Texto general */
            .stMarkdown, p, span, label, div {
                color: #31333F !important;
            }

            h1, h2, h3, h4, h5, h6 {
                color: #262730 !important;
            }

            /* M√©tricas */
            [data-testid="stMetric"] {
                background-color: #f8f9fa !important;
                padding: 1rem;
                border-radius: 8px;
                border: 1px solid #e6e9ef;
            }

            [data-testid="stMetricValue"] {
                color: #1f77b4 !important;
            }

            [data-testid="stMetricLabel"] {
                color: #666666 !important;
            }

            /* Tabs */
            .stTabs [data-baseweb="tab-list"] {
                background-color: #f0f2f6 !important;
            }

            .stTabs [data-baseweb="tab"] {
                color: #666666 !important;
                background-color: #ffffff !important;
            }

            .stTabs [aria-selected="true"] {
                color: #1f77b4 !important;
                background-color: #ffffff !important;
                border-bottom-color: #1f77b4 !important;
            }

            /* Radio buttons */
            [data-testid="stRadio"] label {
                color: #31333F !important;
            }

            /* Dividers */
            hr {
                border-color: #e6e9ef !important;
            }

            /* Success/Info boxes */
            .stAlert {
                background-color: #f8f9fa !important;
                color: #31333F !important;
                border: 1px solid #e6e9ef;
            }
        </style>
        """

# Aplicar estilos CSS seg√∫n el tema seleccionado
st.markdown(get_theme_css(st.session_state.theme), unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Carga todos los datos necesarios"""
    base_dir = Path(__file__).parent.parent / "data"

    # Cargar publicaciones
    publications = pd.read_csv(base_dir / "publications_base.csv")

    # Intentar cargar clasificaciones (si existen)
    try:
        with open(base_dir / "classifications" / "ods_classification_embeddings.json", 'r', encoding='utf-8') as f:
            ods_full = json.load(f)
            # Extraer solo la lista de art√≠culos
            ods_data = ods_full.get('articulos', [])
    except FileNotFoundError:
        ods_data = []

    # Cargar clasificaci√≥n PRONACES (embeddings)
    try:
        with open(base_dir / "classifications" / "pronaces_classification_embeddings.json", 'r', encoding='utf-8') as f:
            pronaces_full = json.load(f)
            # Extraer solo la lista de art√≠culos
            pronaces_data = pronaces_full.get('articulos', [])
    except FileNotFoundError:
        pronaces_data = []

    try:
        with open(base_dir / "classifications" / "themes_classification.json", 'r', encoding='utf-8') as f:
            themes_data = json.load(f)
    except FileNotFoundError:
        themes_data = []

    try:
        with open(base_dir / "classifications" / "lineas_classification.json", 'r', encoding='utf-8') as f:
            lineas_data = json.load(f)
    except FileNotFoundError:
        lineas_data = None

    return publications, ods_data, pronaces_data, themes_data, lineas_data


@st.cache_data
def load_pubmed_metadata():
    """Carga metadata enriquecida de PubMed con citaciones, MeSH terms, keywords, etc."""
    base_dir = Path(__file__).parent.parent / "data" / "pubmed_extracted"

    try:
        with open(base_dir / "metadata_updated_20251024_043156.json", 'r', encoding='utf-8') as f:
            pubmed_data = json.load(f)
        return pubmed_data
    except FileNotFoundError:
        return []


def create_year_evolution_chart(df):
    """Gr√°fica de evoluci√≥n anual de publicaciones con tema DCNT"""
    publications_per_year = df.groupby('a√±o').size().reset_index(name='Publicaciones')

    # Colores inspirados en el logo del DCNT (verde-azul institucional)
    # Con gradiente que mejora la visibilidad de todos los a√±os
    dcnt_colors = {
        2019: '#004C6D',  # Azul oscuro
        2020: '#005F89',  # Azul medio-oscuro
        2021: '#0072A5',  # Azul medio
        2022: '#0086C1',  # Azul claro (m√°s visible)
        2023: '#009ADD',  # Azul-cyan
        2024: '#00AEF9',  # Cyan brillante
        2025: '#17C3FF'   # Cyan muy brillante
    }

    # Asignar colores espec√≠ficos a cada a√±o
    publications_per_year['color'] = publications_per_year['a√±o'].map(dcnt_colors)

    fig = px.bar(
        publications_per_year,
        x='a√±o',
        y='Publicaciones',
        title='Evoluci√≥n de la Productividad Cient√≠fica DCNT-UdeG (2019-2025)',
        labels={'a√±o': 'A√±o', 'Publicaciones': 'N√∫mero de Publicaciones'},
        color='a√±o',
        color_discrete_map=dcnt_colors,
        text='Publicaciones'
    )

    # Agregar valores en las barras para mejor legibilidad
    fig.update_traces(
        texttemplate='%{text}',
        textposition='outside',
        textfont_size=12,
        marker_line_color='rgba(0,0,0,0.3)',
        marker_line_width=1.5
    )

    fig.update_layout(
        xaxis=dict(
            tickmode='linear',
            title_font=dict(size=14, family='Arial, sans-serif', color='#2c3e50'),
            tickfont=dict(size=12)
        ),
        yaxis=dict(
            title_font=dict(size=14, family='Arial, sans-serif', color='#2c3e50'),
            tickfont=dict(size=12),
            gridcolor='rgba(0,0,0,0.1)'
        ),
        title=dict(
            font=dict(size=16, family='Arial, sans-serif', color='#2c3e50'),
            x=0.5,
            xanchor='center'
        ),
        hovermode='x unified',
        height=450,
        showlegend=False,
        plot_bgcolor='rgba(240,248,255,0.3)',  # Fondo muy suave azul
        paper_bgcolor='white'
    )

    # Agregar anotaci√≥n para destacar el a√±o 2022 si tiene pocas publicaciones
    year_2022_data = publications_per_year[publications_per_year['a√±o'] == 2022]
    if not year_2022_data.empty and year_2022_data.iloc[0]['Publicaciones'] < 10:
        fig.add_annotation(
            x=2022,
            y=year_2022_data.iloc[0]['Publicaciones'] + 2,
            text="‚Üì",
            showarrow=False,
            font=dict(size=20, color='#0086C1')
        )

    return fig


def create_ods_distribution(ods_data):
    """Gr√°fica de distribuci√≥n por ODS con barras horizontales para mejor visibilidad"""
    if not ods_data:
        return None

    # Contar ODS
    ods_counter = Counter()
    total_articulos = len(ods_data)

    for pub in ods_data:
        for ods in pub.get('ods_principales', []):
            ods_name = f"ODS {ods.get('numero')}: {ods.get('nombre', '')}"
            ods_counter[ods_name] += 1

    if not ods_counter:
        return None

    # Crear DataFrame y ordenar por n√∫mero de ODS
    ods_list = []
    for ods_name, count in ods_counter.items():
        ods_num = int(ods_name.split(':')[0].replace('ODS ', ''))
        percentage = (count / total_articulos) * 100
        ods_list.append({
            'ODS': ods_name,
            'Publicaciones': count,
            'Porcentaje': percentage,
            'ODS_Num': ods_num,
            'Texto': f"{count} ({percentage:.1f}%)"
        })

    ods_df = pd.DataFrame(ods_list)
    ods_df = ods_df.sort_values('ODS_Num')

    # Definir colores por ODS (colores institucionales y tem√°ticos)
    colors_map = {
        'ODS 1: Fin de la Pobreza': '#E5243B',
        'ODS 2: Hambre Cero': '#DDA83A',
        'ODS 3: Salud y Bienestar': '#4C9F38',
        'ODS 5: Igualdad de G√©nero': '#FF3A21',
        'ODS 10: Reducir Desigualdades': '#DD1367',
        'ODS 12: Producci√≥n y Consumo': '#BF8B2E',
        'ODS 15: Vida de Ecosistemas': '#56C02B',
        'ODS 17: Alianzas': '#00689D'
    }

    # Gr√°fica de barras horizontales
    fig = px.bar(
        ods_df,
        x='Publicaciones',
        y='ODS',
        orientation='h',
        title='Distribuci√≥n de Publicaciones por Objetivos de Desarrollo Sostenible',
        text='Texto',
        color='ODS',
        color_discrete_map=colors_map,
        labels={'Publicaciones': 'N√∫mero de Publicaciones'}
    )

    # Personalizar el gr√°fico
    fig.update_traces(
        textposition='outside',
        textfont_size=12,
        hovertemplate='<b>%{y}</b><br>Publicaciones: %{x}<br><extra></extra>'
    )

    fig.update_layout(
        height=400,
        showlegend=False,
        xaxis=dict(
            title='N√∫mero de Publicaciones',
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)'
        ),
        yaxis=dict(
            title='',
            automargin=True
        ),
        plot_bgcolor='rgba(240,248,255,0.3)',
        paper_bgcolor='white',
        font=dict(size=11)
    )

    return fig


def filter_articulos_by_ods(ods_data, ods_num):
    """
    Filtra art√≠culos por n√∫mero de ODS

    Args:
        ods_data: Lista de art√≠culos con clasificaci√≥n ODS
        ods_num: N√∫mero de ODS (2, 3, 10, 12, etc.)

    Returns:
        DataFrame con art√≠culos filtrados
    """
    articulos_filtrados = []

    for art in ods_data:
        for ods in art.get('ods_principales', []):
            if ods.get('numero') == ods_num:
                articulos_filtrados.append({
                    'A√±o': art.get('a√±o', ''),
                    'T√≠tulo': art.get('titulo', ''),
                    'Justificaci√≥n': art.get('justificacion', 'N/A')[:100] + '...' if len(art.get('justificacion', '')) > 100 else art.get('justificacion', 'N/A')
                })
                break

    if not articulos_filtrados:
        return None

    df = pd.DataFrame(articulos_filtrados)
    df = df.sort_values('A√±o', ascending=False)
    return df


def get_ods_stats(ods_data):
    """
    Obtiene estad√≠sticas por ODS

    Returns:
        dict con conteo de art√≠culos por ODS
    """
    stats = {}
    for pub in ods_data:
        for ods in pub.get('ods_principales', []):
            num = ods.get('numero')
            if num:
                stats[num] = stats.get(num, 0) + 1
    return stats


def create_pronaces_heatmap(pronaces_data, publications_df):
    """Matriz de calor PRONACES vs A√±os"""
    if not pronaces_data:
        return None

    # Crear matriz
    years = sorted(publications_df['a√±o'].unique())
    pronaces_list = []
    matrix_data = []

    # Recopilar todos los PRONACES √∫nicos
    all_pronaces = set()
    for pub in pronaces_data:
        for pron in pub.get('pronaces_principales', []):
            all_pronaces.add(pron.get('nombre', ''))

    pronaces_list = sorted(list(all_pronaces))

    # Crear matriz de conteo
    matrix = {year: {pron: 0 for pron in pronaces_list} for year in years}

    for pub in pronaces_data:
        year = pub.get('a√±o')
        for pron in pub.get('pronaces_principales', []):
            pron_name = pron.get('nombre', '')
            if pron_name in pronaces_list and year in matrix:
                matrix[year][pron_name] += 1

    # Convertir a formato para heatmap
    z_data = [[matrix[year][pron] for year in years] for pron in pronaces_list]

    fig = go.Figure(data=go.Heatmap(
        z=z_data,
        x=years,
        y=pronaces_list,
        colorscale='YlOrRd',
        text=z_data,
        texttemplate='%{text}',
        textfont={"size": 12},
        colorbar=dict(title="Publicaciones")
    ))

    fig.update_layout(
        title='Matriz de Calor: PRONACES vs A√±os',
        xaxis_title='A√±o',
        yaxis_title='PRONACES',
        height=500
    )

    return fig


def create_themes_treemap(themes_data):
    """Treemap jer√°rquico de temas de investigaci√≥n"""
    if not themes_data:
        return None

    # Contar temas
    theme_counter = Counter()
    for pub in themes_data:
        for theme in pub.get('temas', []):
            theme_name = theme.get('nombre', '')
            if theme_name:
                theme_counter[theme_name] += 1

    if not theme_counter:
        return None

    # Preparar datos para treemap
    themes = list(theme_counter.keys())
    values = list(theme_counter.values())

    # Crear treemap
    fig = go.Figure(go.Treemap(
        labels=themes,
        parents=["Temas de Investigaci√≥n"] * len(themes),
        values=values,
        textinfo="label+value+percent parent",
        textfont=dict(size=14),
        marker=dict(
            colorscale='Viridis',
            cmid=sum(values)/len(values),
            colorbar=dict(
                title="Publicaciones",
                thickness=20,
                len=0.7
            )
        ),
        hovertemplate='<b>%{label}</b><br>Publicaciones: %{value}<br>Porcentaje: %{percentParent}<extra></extra>'
    ))

    fig.update_layout(
        title='Distribuci√≥n Jer√°rquica de Temas (Treemap)',
        height=600,
        margin=dict(l=10, r=10, t=50, b=10)
    )

    return fig


def create_themes_cooccurrence(themes_data):
    """Matriz de co-ocurrencia de temas"""
    if not themes_data:
        return None

    # Obtener todos los temas √∫nicos
    all_themes = set()
    for pub in themes_data:
        for theme in pub.get('temas', []):
            theme_name = theme.get('nombre', '')
            if theme_name:
                all_themes.add(theme_name)

    all_themes = sorted(list(all_themes))

    if len(all_themes) == 0:
        return None

    # Crear matriz de co-ocurrencia
    matrix = [[0 for _ in all_themes] for _ in all_themes]

    for pub in themes_data:
        pub_themes = [t.get('nombre', '') for t in pub.get('temas', []) if t.get('nombre', '')]

        # Contar co-ocurrencias
        for i, theme1 in enumerate(all_themes):
            for j, theme2 in enumerate(all_themes):
                if theme1 in pub_themes and theme2 in pub_themes:
                    if i != j:  # No contar auto-correlaci√≥n
                        matrix[i][j] += 1

    # Crear heatmap
    fig = go.Figure(data=go.Heatmap(
        z=matrix,
        x=all_themes,
        y=all_themes,
        colorscale='YlOrRd',
        text=matrix,
        texttemplate='%{text}',
        textfont={"size": 10},
        hovertemplate='%{y} co-ocurre con %{x}<br>Veces: %{z}<extra></extra>',
        colorbar=dict(
            title="Co-ocurrencias",
            thickness=20,
            len=0.7
        )
    ))

    fig.update_layout(
        title='Matriz de Co-ocurrencia de Temas',
        xaxis_title='Temas',
        yaxis_title='Temas',
        height=700,
        xaxis=dict(tickangle=45),
        yaxis=dict(tickangle=0)
    )

    return fig


def create_themes_sunburst(themes_data):
    """Gr√°fica sunburst de temas por categor√≠a"""
    if not themes_data:
        return None

    # Categorizar temas
    categorias = {
        'Enfermedades Metab√≥licas': ['OBESIDAD_SOBREPESO', 'DIABETES', 'LIPIDOS_COLESTEROL', 'INFLAMACION_METABOLICA'],
        'Enfermedades Inmunol√≥gicas': ['ENFERMEDADES_AUTOINMUNES', 'COVID19'],
        'Factores de Estilo de Vida': ['ACTIVIDAD_FISICA', 'MICROBIOTA_INTESTINAL'],
        'Gen√©tica y Nutrici√≥n': ['GENETICA_NUTRICION'],
        'Oncolog√≠a': ['CANCER']
    }

    # Contar temas
    theme_counter = Counter()
    for pub in themes_data:
        for theme in pub.get('temas', []):
            theme_name = theme.get('nombre', '')
            if theme_name:
                theme_counter[theme_name] += 1

    if not theme_counter:
        return None

    # Preparar datos para sunburst
    labels = ['Todos los Temas']
    parents = ['']
    values = [0]  # Se calcular√° despu√©s

    # Agregar categor√≠as
    for categoria in categorias.keys():
        labels.append(categoria)
        parents.append('Todos los Temas')
        values.append(0)  # Se calcular√° despu√©s

    # Agregar temas individuales
    total = 0
    for categoria, temas in categorias.items():
        cat_total = 0
        for tema in temas:
            if tema in theme_counter:
                count = theme_counter[tema]
                labels.append(tema)
                parents.append(categoria)
                values.append(count)
                cat_total += count
                total += count
        # Actualizar total de categor√≠a
        cat_idx = labels.index(categoria)
        values[cat_idx] = cat_total

    values[0] = total  # Total general

    # Crear sunburst
    fig = go.Figure(go.Sunburst(
        labels=labels,
        parents=parents,
        values=values,
        branchvalues="total",
        marker=dict(
            colorscale='Viridis',
            cmid=sum([v for v in values if v > 0])/len([v for v in values if v > 0])
        ),
        hovertemplate='<b>%{label}</b><br>Publicaciones: %{value}<br>%{percentParent}<extra></extra>'
    ))

    fig.update_layout(
        title='Jerarqu√≠a de Temas por Categor√≠a (Sunburst)',
        height=700,
        margin=dict(l=0, r=0, t=50, b=0)
    )

    return fig


def create_themes_distribution(themes_data):
    """Gr√°fica de barras de distribuci√≥n por tema"""
    if not themes_data:
        return None

    # Contar temas
    theme_counter = Counter()
    for pub in themes_data:
        for theme in pub.get('temas', []):
            theme_name = theme.get('nombre', '')
            if theme_name:
                theme_counter[theme_name] += 1

    if not theme_counter:
        return None

    # Crear DataFrame
    themes_df = pd.DataFrame(theme_counter.most_common(15), columns=['Tema', 'Publicaciones'])

    fig = px.bar(
        themes_df,
        x='Publicaciones',
        y='Tema',
        orientation='h',
        title='Top 15 Temas de Investigaci√≥n',
        labels={'Publicaciones': 'N√∫mero de Publicaciones', 'Tema': 'Tema'},
        color='Publicaciones',
        color_continuous_scale='Teal'
    )

    fig.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})

    return fig


# ============================ FUNCIONES AN√ÅLISIS MeSH ============================

def create_mesh_distribution(pubmed_data, top_n=20):
    """Distribuci√≥n de los t√©rminos MeSH m√°s frecuentes"""
    if not pubmed_data:
        return None

    # Contar t√©rminos MeSH
    mesh_counter = Counter()
    for article in pubmed_data:
        mesh_terms = article.get('mesh_terms', [])
        mesh_counter.update(mesh_terms)

    if not mesh_counter:
        return None

    # Top N t√©rminos
    top_mesh = mesh_counter.most_common(top_n)
    mesh_df = pd.DataFrame(top_mesh, columns=['T√©rmino MeSH', 'Frecuencia'])

    # Crear gr√°fico de barras
    fig = px.bar(
        mesh_df,
        y='T√©rmino MeSH',
        x='Frecuencia',
        orientation='h',
        title=f'Top {top_n} T√©rminos MeSH m√°s Frecuentes',
        labels={'T√©rmino MeSH': 'T√©rmino MeSH', 'Frecuencia': 'N√∫mero de Art√≠culos'},
        color='Frecuencia',
        color_continuous_scale='Blues'
    )

    fig.update_layout(
        height=600,
        yaxis={'categoryorder': 'total ascending'},
        showlegend=False
    )

    return fig


def create_mesh_treemap(pubmed_data, top_n=30):
    """Treemap de t√©rminos MeSH"""
    if not pubmed_data:
        return None

    # Contar t√©rminos MeSH
    mesh_counter = Counter()
    for article in pubmed_data:
        mesh_terms = article.get('mesh_terms', [])
        mesh_counter.update(mesh_terms)

    if not mesh_counter:
        return None

    # Top N t√©rminos
    top_mesh = mesh_counter.most_common(top_n)

    # Preparar datos para treemap
    labels = ['T√©rminos MeSH'] + [term for term, _ in top_mesh]
    parents = [''] + ['T√©rminos MeSH'] * len(top_mesh)
    values = [0] + [count for _, count in top_mesh]

    # Calcular total
    values[0] = sum(values[1:])

    fig = go.Figure(go.Treemap(
        labels=labels,
        parents=parents,
        values=values,
        textinfo="label+value+percent parent",
        marker=dict(colorscale='Blues', cmid=sum(values[1:]) / len(values[1:])),
        hovertemplate='<b>%{label}</b><br>Art√≠culos: %{value}<br>%{percentParent}<extra></extra>'
    ))

    fig.update_layout(
        title=f'Treemap de Top {top_n} T√©rminos MeSH',
        height=600,
        margin=dict(l=10, r=10, t=50, b=10)
    )

    return fig


def create_mesh_cooccurrence(pubmed_data, top_n=15):
    """Matriz de co-ocurrencia de t√©rminos MeSH"""
    if not pubmed_data:
        return None

    # Obtener los t√©rminos MeSH m√°s frecuentes
    mesh_counter = Counter()
    for article in pubmed_data:
        mesh_terms = article.get('mesh_terms', [])
        mesh_counter.update(mesh_terms)

    if not mesh_counter:
        return None

    # Top N t√©rminos
    top_mesh_terms = [term for term, _ in mesh_counter.most_common(top_n)]

    # Crear matriz de co-ocurrencia
    matrix = [[0 for _ in top_mesh_terms] for _ in top_mesh_terms]

    for article in pubmed_data:
        article_mesh = article.get('mesh_terms', [])
        # Solo considerar t√©rminos que est√°n en el top N
        article_mesh_filtered = [term for term in article_mesh if term in top_mesh_terms]

        # Contar co-ocurrencias
        for i, term1 in enumerate(top_mesh_terms):
            for j, term2 in enumerate(top_mesh_terms):
                if term1 in article_mesh_filtered and term2 in article_mesh_filtered:
                    if i != j:  # No contar auto-correlaci√≥n
                        matrix[i][j] += 1

    # Crear heatmap
    fig = go.Figure(data=go.Heatmap(
        z=matrix,
        x=top_mesh_terms,
        y=top_mesh_terms,
        colorscale='YlOrRd',
        text=matrix,
        texttemplate='%{text}',
        textfont={"size": 10},
        hovertemplate='%{y} co-ocurre con %{x}<br>Veces: %{z}<extra></extra>',
        colorbar=dict(
            title="Co-ocurrencias",
            thickness=20,
            len=0.7
        )
    ))

    fig.update_layout(
        title=f'Matriz de Co-ocurrencia de Top {top_n} T√©rminos MeSH',
        xaxis_title='T√©rminos MeSH',
        yaxis_title='T√©rminos MeSH',
        height=700,
        xaxis=dict(tickangle=45),
        yaxis=dict(tickangle=0)
    )

    return fig


def get_top_mesh_connections(pubmed_data, top_n=5):
    """Obtiene las co-ocurrencias m√°s fuertes entre t√©rminos MeSH"""
    if not pubmed_data:
        return []

    connections = []

    for article in pubmed_data:
        mesh_terms = article.get('mesh_terms', [])
        # Crear pares de t√©rminos
        for i, term1 in enumerate(mesh_terms):
            for term2 in mesh_terms[i+1:]:
                connections.append((term1, term2))

    # Contar co-ocurrencias
    connection_counter = Counter(connections)

    return connection_counter.most_common(top_n)


# ============================ FUNCIONES AN√ÅLISIS KEYWORDS ============================

def create_keywords_distribution(pubmed_data, top_n=20):
    """Distribuci√≥n de keywords (palabras clave de autores)"""
    if not pubmed_data:
        return None

    # Contar keywords
    keyword_counter = Counter()
    for article in pubmed_data:
        keywords = article.get('keywords', [])
        if keywords and isinstance(keywords, list):
            keyword_counter.update(keywords)

    if not keyword_counter:
        return None

    # Top N keywords
    top_keywords = keyword_counter.most_common(top_n)
    keywords_df = pd.DataFrame(top_keywords, columns=['Keyword', 'Frecuencia'])

    # Crear gr√°fico de barras
    fig = px.bar(
        keywords_df,
        y='Keyword',
        x='Frecuencia',
        orientation='h',
        title=f'Top {top_n} Keywords m√°s Frecuentes (Palabras Clave de Autores)',
        labels={'Keyword': 'Keyword', 'Frecuencia': 'N√∫mero de Art√≠culos'},
        color='Frecuencia',
        color_continuous_scale='Greens'
    )

    fig.update_layout(
        height=600,
        yaxis={'categoryorder': 'total ascending'},
        showlegend=False
    )

    return fig


def create_combined_terms_distribution(pubmed_data, top_n=25):
    """Distribuci√≥n combinada de t√©rminos MeSH y keywords"""
    if not pubmed_data:
        return None

    # Contar MeSH y keywords por separado
    mesh_counter = Counter()
    keyword_counter = Counter()

    for article in pubmed_data:
        mesh_terms = article.get('mesh_terms', [])
        keywords = article.get('keywords', [])

        mesh_counter.update(mesh_terms)
        if keywords and isinstance(keywords, list):
            keyword_counter.update(keywords)

    # Combinar ambos contadores
    combined_counter = Counter()

    # Agregar MeSH terms con etiqueta
    for term, count in mesh_counter.items():
        combined_counter[term] = combined_counter.get(term, 0) + count

    # Agregar keywords con etiqueta
    for kw, count in keyword_counter.items():
        combined_counter[kw] = combined_counter.get(kw, 0) + count

    if not combined_counter:
        return None

    # Top N t√©rminos combinados
    top_combined = combined_counter.most_common(top_n)

    # Identificar fuente de cada t√©rmino
    sources = []
    for term, count in top_combined:
        if term in mesh_counter and term in keyword_counter:
            sources.append('Ambos')
        elif term in mesh_counter:
            sources.append('MeSH')
        else:
            sources.append('Keywords')

    combined_df = pd.DataFrame({
        'T√©rmino': [term for term, _ in top_combined],
        'Frecuencia': [count for _, count in top_combined],
        'Fuente': sources
    })

    # Crear gr√°fico de barras con colores por fuente
    fig = px.bar(
        combined_df,
        y='T√©rmino',
        x='Frecuencia',
        orientation='h',
        color='Fuente',
        title=f'Top {top_n} T√©rminos Combinados (MeSH + Keywords)',
        labels={'T√©rmino': 'T√©rmino', 'Frecuencia': 'N√∫mero de Art√≠culos'},
        color_discrete_map={'MeSH': '#2E86AB', 'Keywords': '#A23B72', 'Ambos': '#F18F01'}
    )

    fig.update_layout(
        height=700,
        yaxis={'categoryorder': 'total ascending'}
    )

    return fig


def create_mesh_vs_keywords_comparison(pubmed_data):
    """Comparaci√≥n de cobertura entre MeSH y Keywords"""
    if not pubmed_data:
        return None

    articles_with_mesh = 0
    articles_with_keywords = 0
    articles_with_both = 0
    articles_with_none = 0

    for article in pubmed_data:
        has_mesh = bool(article.get('mesh_terms', []))
        has_keywords = bool(article.get('keywords', []))

        if has_mesh and has_keywords:
            articles_with_both += 1
        elif has_mesh:
            articles_with_mesh += 1
        elif has_keywords:
            articles_with_keywords += 1
        else:
            articles_with_none += 1

    # Crear gr√°fico de pastel
    labels = ['Solo MeSH', 'Solo Keywords', 'Ambos', 'Ninguno']
    values = [articles_with_mesh, articles_with_keywords, articles_with_both, articles_with_none]
    colors = ['#2E86AB', '#A23B72', '#F18F01', '#CCCCCC']

    fig = go.Figure(data=[go.Pie(
        labels=labels,
        values=values,
        hole=0.4,
        marker=dict(colors=colors),
        textinfo='label+value+percent',
        hovertemplate='<b>%{label}</b><br>Art√≠culos: %{value}<br>Porcentaje: %{percent}<extra></extra>'
    )])

    fig.update_layout(
        title='Cobertura de T√©rminos MeSH vs Keywords en Art√≠culos',
        height=500
    )

    return fig


# ============================ FUNCIONES L√çNEAS DE INVESTIGACI√ìN ============================

def create_lineas_distribution_chart(lineas_data):
    """Gr√°fica de distribuci√≥n de art√≠culos por l√≠nea de investigaci√≥n"""
    if not lineas_data or 'estadisticas' not in lineas_data:
        return None

    stats = lineas_data['estadisticas']
    por_linea = stats.get('por_linea', {})

    # Nombres de l√≠neas
    lineas_nombres = {
        '1': 'L√≠nea 1: Bases Moleculares y Gen√≥mica Nutricional',
        '2': 'L√≠nea 2: Epidemiolog√≠a Cl√≠nica y Factores de Riesgo',
        '3': 'L√≠nea 3: Salud Poblacional y Pol√≠ticas P√∫blicas'
    }

    # Preparar datos
    data = []
    for linea_num in ['1', '2', '3']:
        count = por_linea.get(linea_num, 0)
        data.append({
            'L√≠nea': lineas_nombres[linea_num],
            'Art√≠culos': count,
            'Porcentaje': f"{count/stats['total_articulos']*100:.1f}%"
        })

    # Crear gr√°fica de barras horizontal
    fig = go.Figure()

    fig.add_trace(go.Bar(
        y=[d['L√≠nea'] for d in data],
        x=[d['Art√≠culos'] for d in data],
        text=[f"{d['Art√≠culos']} ({d['Porcentaje']})" for d in data],
        textposition='outside',
        orientation='h',
        marker=dict(
            color=['#1f77b4', '#ff7f0e', '#2ca02c'],
            line=dict(color='#000', width=1)
        )
    ))

    fig.update_layout(
        title='Distribuci√≥n de Art√≠culos por L√≠nea de Investigaci√≥n',
        xaxis_title='N√∫mero de Art√≠culos (totales: l√≠neas principales + secundarias)',
        yaxis_title='',
        height=300,
        showlegend=False,
        margin=dict(l=50, r=150, t=50, b=50)
    )

    return fig


def create_upset_plot(lineas_data):
    """UpSet Plot mostrando intersecciones de l√≠neas de investigaci√≥n"""
    if not lineas_data or 'articulos' not in lineas_data:
        return None

    # Nombres de l√≠neas
    lineas_nombres = {
        1: 'L1: Molecular y Gen√≥mica',
        2: 'L2: Cl√≠nica y Epidemiolog√≠a',
        3: 'L3: Poblacional y Pol√≠ticas'
    }

    # Contar todos los art√≠culos por l√≠nea (para barras laterales)
    totales_por_linea = {1: 0, 2: 0, 3: 0}

    # Contar intersecciones
    intersecciones = {}

    for art in lineas_data['articulos']:
        lineas = art['clasificacion'].get('lineas_principales', [])
        lineas_nums = sorted(set([l['linea'] for l in lineas]))

        # Actualizar totales
        for num in lineas_nums:
            totales_por_linea[num] += 1

        # Crear clave para la intersecci√≥n
        key = tuple(lineas_nums)
        intersecciones[key] = intersecciones.get(key, 0) + 1

    # Ordenar intersecciones por tama√±o (descendente)
    intersecciones_sorted = sorted(intersecciones.items(), key=lambda x: x[1], reverse=True)

    if not intersecciones_sorted:
        return None

    # Preparar datos para el plot
    from plotly.subplots import make_subplots

    # Crear subplots: barras arriba, matriz abajo
    fig = make_subplots(
        rows=2, cols=1,
        row_heights=[0.7, 0.3],
        vertical_spacing=0.02,
        subplot_titles=('Tama√±o de Intersecciones', 'Combinaciones de L√≠neas')
    )

    # Preparar datos para barras superiores (intersecciones)
    x_labels = []
    y_values = []
    hover_texts = []

    for idx, (combo, count) in enumerate(intersecciones_sorted):
        # Crear etiqueta
        if len(combo) == 1:
            label = f"Solo L{combo[0]}"
        else:
            label = " ‚à© ".join([f"L{n}" for n in combo])

        x_labels.append(label)
        y_values.append(count)

        # Crear hover text detallado
        lineas_str = " + ".join([lineas_nombres[n] for n in combo])
        hover_texts.append(f"{count} art√≠culos<br>{lineas_str}")

    # Agregar barras superiores
    fig.add_trace(
        go.Bar(
            x=x_labels,
            y=y_values,
            text=y_values,
            textposition='outside',
            marker=dict(color='#1f77b4'),
            hovertext=hover_texts,
            hoverinfo='text',
            showlegend=False
        ),
        row=1, col=1
    )

    # Preparar matriz de dots para panel inferior
    # Crear una matriz donde cada fila es una l√≠nea, cada columna es una intersecci√≥n
    for linea_num in [3, 2, 1]:  # Invertido para que L1 quede arriba
        y_dots = []

        for combo, _ in intersecciones_sorted:
            if linea_num in combo:
                y_dots.append(linea_num)
            else:
                y_dots.append(None)

        # Agregar dots
        fig.add_trace(
            go.Scatter(
                x=x_labels,
                y=y_dots,
                mode='markers',
                marker=dict(
                    size=12,
                    color='#2ca02c',
                    symbol='circle'
                ),
                showlegend=False,
                hoverinfo='skip'
            ),
            row=2, col=1
        )

        # Agregar l√≠neas verticales conectando dots en cada intersecci√≥n
        for idx, (combo, _) in enumerate(intersecciones_sorted):
            if len(combo) > 1 and linea_num in combo:
                # Encontrar las otras l√≠neas en esta combo
                lineas_en_combo = [l for l in combo if l in [1, 2, 3]]
                if len(lineas_en_combo) > 1:
                    y_min = min(lineas_en_combo)
                    y_max = max(lineas_en_combo)

                    fig.add_trace(
                        go.Scatter(
                            x=[x_labels[idx], x_labels[idx]],
                            y=[y_min, y_max],
                            mode='lines',
                            line=dict(color='#2ca02c', width=3),
                            showlegend=False,
                            hoverinfo='skip'
                        ),
                        row=2, col=1
                    )

    # Actualizar layout
    fig.update_xaxes(title_text="", row=1, col=1)
    fig.update_yaxes(title_text="Art√≠culos", row=1, col=1)

    fig.update_xaxes(title_text="", showticklabels=False, row=2, col=1)
    fig.update_yaxes(
        title_text="L√≠neas",
        tickmode='array',
        tickvals=[1, 2, 3],
        ticktext=['L1', 'L2', 'L3'],
        range=[0.5, 3.5],
        row=2, col=1
    )

    total_articulos = len(lineas_data['articulos'])

    fig.update_layout(
        title=f'UpSet Plot: Intersecciones de L√≠neas de Investigaci√≥n ({total_articulos} art√≠culos)',
        height=600,
        showlegend=False,
        font=dict(size=11)
    )

    return fig


def create_lineas_cooccurrence_matrix(lineas_data):
    """Matriz de co-ocurrencia entre l√≠neas de investigaci√≥n"""
    if not lineas_data or 'articulos' not in lineas_data:
        return None

    # Inicializar matriz 3x3
    matrix = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
    lineas_nombres = ['L1: Gen√≥mica', 'L2: Salud P√∫blica', 'L3: Alimentaci√≥n']

    # Contar co-ocurrencias
    for art in lineas_data['articulos']:
        lineas_principales = [l['linea'] for l in art['clasificacion']['lineas_principales']]

        # Para cada par de l√≠neas
        for i in range(1, 4):
            for j in range(1, 4):
                if i != j and i in lineas_principales and j in lineas_principales:
                    matrix[i-1][j-1] += 1

    # Crear heatmap
    fig = go.Figure(data=go.Heatmap(
        z=matrix,
        x=lineas_nombres,
        y=lineas_nombres,
        colorscale='Blues',
        text=matrix,
        texttemplate='%{text} art√≠culos',
        textfont={"size": 12},
        hovertemplate='%{y} + %{x}<br>Co-ocurrencias: %{z}<extra></extra>',
        colorbar=dict(
            title="Art√≠culos",
            thickness=15,
            len=0.7
        )
    ))

    fig.update_layout(
        title='Matriz de Co-ocurrencia entre L√≠neas',
        xaxis_title='',
        yaxis_title='',
        height=400,
        xaxis=dict(side='bottom'),
        yaxis=dict(autorange='reversed')
    )

    return fig


# ============================================================================
# NUEVAS FUNCIONES PARA AN√ÅLISIS ENRIQUECIDO CON METADATA DE PUBMED
# ============================================================================

def create_mesh_terms_chart(pubmed_data):
    """Gr√°fica de barras horizontal con los t√©rminos MeSH m√°s frecuentes"""
    if not pubmed_data:
        return None

    # T√©rminos demogr√°ficos a excluir
    demographic_terms = {
        'Humans', 'Female', 'Male', 'Adult', 'Middle Aged', 'Aged',
        'Animals', 'Mice', 'Rats', 'Young Adult', 'Aged, 80 and over',
        'Child', 'Adolescent', 'Infant'
    }

    # Extraer todos los MeSH terms
    all_mesh = []
    for article in pubmed_data:
        if article.get('mesh_terms'):
            for term in article['mesh_terms']:
                if term not in demographic_terms:
                    all_mesh.append(term)

    if not all_mesh:
        return None

    # Contar frecuencias
    from collections import Counter
    mesh_counts = Counter(all_mesh).most_common(30)

    # Crear dataframe
    df_mesh = pd.DataFrame(mesh_counts, columns=['Term', 'Count'])

    # Crear gr√°fica de barras horizontal
    fig = px.bar(
        df_mesh,
        y='Term',
        x='Count',
        orientation='h',
        title='Top 30 T√©rminos MeSH - Vocabulario Biom√©dico Internacional',
        labels={'Term': 'T√©rmino MeSH', 'Count': 'N√∫mero de Art√≠culos'},
        color='Count',
        color_continuous_scale='Blues'
    )

    fig.update_layout(
        height=800,
        yaxis={'categoryorder': 'total ascending'},
        xaxis_title='N√∫mero de Art√≠culos',
        yaxis_title='',
        showlegend=False
    )

    return fig


def create_citations_metrics_and_chart(pubmed_data):
    """Crea m√©tricas de impacto y gr√°fica de distribuci√≥n de citaciones"""
    if not pubmed_data:
        return None, None

    # Extraer citaciones
    citations = [art.get('cited_by_count', 0) for art in pubmed_data if art.get('cited_by_count')]

    if not citations:
        return None, None

    # Calcular m√©tricas
    total_citations = sum(citations)
    avg_citations = sum(citations) / len(citations)
    max_citations = max(citations)

    # Calcular h-index simplificado
    sorted_citations = sorted(citations, reverse=True)
    h_index = 0
    for i, cites in enumerate(sorted_citations, 1):
        if cites >= i:
            h_index = i
        else:
            break

    metrics = {
        'total': total_citations,
        'average': avg_citations,
        'max': max_citations,
        'h_index': h_index,
        'count': len(citations)
    }

    # Crear histograma
    fig = go.Figure()

    fig.add_trace(go.Histogram(
        x=citations,
        nbinsx=20,
        marker_color='#1f77b4',
        hovertemplate='Citaciones: %{x}<br>Art√≠culos: %{y}<extra></extra>'
    ))

    fig.update_layout(
        title='Distribuci√≥n de Citaciones por Art√≠culo',
        xaxis_title='N√∫mero de Citaciones',
        yaxis_title='N√∫mero de Art√≠culos',
        height=400,
        showlegend=False
    )

    return metrics, fig


def create_top_cited_articles(pubmed_data, top_n=10):
    """Retorna los art√≠culos m√°s citados"""
    if not pubmed_data:
        return []

    # Filtrar art√≠culos con citaciones
    cited_articles = [
        {
            'pmid': art.get('pmid', 'N/A'),
            'title': art.get('title', art.get('original_title', 'Sin t√≠tulo'))[:150],
            'year': art.get('original_year', 'N/A'),
            'citations': art.get('cited_by_count', 0),
            'journal': art.get('journal', art.get('original_journal', 'N/A'))
        }
        for art in pubmed_data
        if art.get('cited_by_count', 0) > 0
    ]

    # Ordenar por citaciones
    cited_articles.sort(key=lambda x: x['citations'], reverse=True)

    return cited_articles[:top_n]


def create_evidence_pyramid_chart(pubmed_data):
    """Crea visualizaci√≥n de pir√°mide de evidencia basada en tipos de publicaci√≥n"""
    if not pubmed_data:
        return None

    # Extraer tipos de publicaci√≥n
    pub_types_count = {}
    for article in pubmed_data:
        for pub_type in article.get('pub_types', []):
            pub_types_count[pub_type] = pub_types_count.get(pub_type, 0) + 1

    # Categorizar en niveles de evidencia
    evidence_levels = {
        'Meta-An√°lisis': pub_types_count.get('Meta-Analysis', 0),
        'Revisiones Sistem√°ticas': pub_types_count.get('Systematic Review', 0) + pub_types_count.get('Scoping Review', 0),
        'RCTs': pub_types_count.get('Randomized Controlled Trial', 0) + pub_types_count.get('Clinical Trial', 0),
        'Estudios Observacionales': pub_types_count.get('Observational Study', 0) + pub_types_count.get('Case-Control Studies', 0),
        'Revisiones': pub_types_count.get('Review', 0),
        'Art√≠culos de Investigaci√≥n': pub_types_count.get('Journal Article', 0)
    }

    # Filtrar solo los que tienen datos
    evidence_levels = {k: v for k, v in evidence_levels.items() if v > 0}

    # Crear gr√°fica de barras horizontal
    df_evidence = pd.DataFrame(list(evidence_levels.items()), columns=['Tipo', 'Cantidad'])

    # Ordenar por nivel de evidencia (de mayor a menor calidad)
    order_map = {
        'Meta-An√°lisis': 6,
        'Revisiones Sistem√°ticas': 5,
        'RCTs': 4,
        'Estudios Observacionales': 3,
        'Revisiones': 2,
        'Art√≠culos de Investigaci√≥n': 1
    }
    df_evidence['order'] = df_evidence['Tipo'].map(order_map)
    df_evidence = df_evidence.sort_values('order', ascending=False)

    fig = px.bar(
        df_evidence,
        y='Tipo',
        x='Cantidad',
        orientation='h',
        title='Pir√°mide de Evidencia Cient√≠fica',
        labels={'Tipo': 'Nivel de Evidencia', 'Cantidad': 'N√∫mero de Art√≠culos'},
        color='Cantidad',
        color_continuous_scale='YlOrRd'
    )

    fig.update_layout(
        height=400,
        yaxis={'categoryorder': 'total ascending'},
        showlegend=False
    )

    return fig


def create_funding_analysis(pubmed_data):
    """Analiza informaci√≥n de financiamiento"""
    if not pubmed_data:
        return None, None

    # Contar art√≠culos con financiamiento
    funded_articles = [art for art in pubmed_data if art.get('grants') and len(art['grants']) > 0]
    funded_count = len(funded_articles)
    total_count = len(pubmed_data)

    # Extraer agencias de financiamiento
    agencies = []
    for article in funded_articles:
        for grant in article.get('grants', []):
            agency = grant.get('agency', 'Unknown')
            if agency:
                agencies.append(agency)

    # Contar frecuencias de agencias (top 10)
    from collections import Counter
    agency_counts = Counter(agencies).most_common(10)

    metrics = {
        'funded': funded_count,
        'total': total_count,
        'percentage': (funded_count / total_count * 100) if total_count > 0 else 0
    }

    if not agency_counts:
        return metrics, None

    # Crear gr√°fica de agencias
    df_agencies = pd.DataFrame(agency_counts, columns=['Agencia', 'Art√≠culos'])

    fig = px.bar(
        df_agencies,
        x='Agencia',
        y='Art√≠culos',
        title='Top 10 Agencias Financiadoras',
        labels={'Agencia': 'Agencia de Financiamiento', 'Art√≠culos': 'N√∫mero de Art√≠culos'},
        color='Art√≠culos',
        color_continuous_scale='Greens'
    )

    fig.update_layout(
        height=400,
        xaxis_tickangle=-45,
        showlegend=False
    )

    return metrics, fig


def create_collaboration_network_data(pubmed_data):
    """Extrae datos de red de colaboraci√≥n institucional"""
    if not pubmed_data:
        return None

    # Extraer instituciones de las afiliaciones
    institutions = []

    for article in pubmed_data:
        article_institutions = set()

        for affiliation in article.get('affiliations', []):
            # Extraer nombre de instituci√≥n (simplificado)
            if affiliation:
                # Buscar palabras clave de instituciones
                if 'Universidad de Guadalajara' in affiliation or 'University of Guadalajara' in affiliation:
                    article_institutions.add('Universidad de Guadalajara')
                elif 'IMSS' in affiliation or 'Mexican Social Security' in affiliation:
                    article_institutions.add('IMSS')
                elif 'UNAM' in affiliation:
                    article_institutions.add('UNAM')
                elif 'IPN' in affiliation or 'Polit√©cnico Nacional' in affiliation:
                    article_institutions.add('IPN')
                elif 'CIATEJ' in affiliation:
                    article_institutions.add('CIATEJ')
                elif 'Universidad Aut√≥noma' in affiliation:
                    article_institutions.add('Universidades Aut√≥nomas')
                elif 'Hospital' in affiliation:
                    article_institutions.add('Hospitales')
                # Agregar m√°s instituciones seg√∫n sea necesario

        if len(article_institutions) > 0:
            institutions.append(list(article_institutions))

    # Contar colaboraciones
    from collections import Counter
    institution_counts = Counter()

    for inst_list in institutions:
        institution_counts.update(inst_list)

    # Top instituciones
    top_institutions = institution_counts.most_common(10)

    return top_institutions


def create_collaboration_map(pubmed_data):
    """Crea mapa mundial de colaboraciones internacionales basado en afiliaciones"""
    if not pubmed_data:
        return None

    # Diccionario de pa√≠ses a buscar en afiliaciones (con c√≥digos ISO)
    country_keywords = {
        'Mexico': {'keywords': ['Mexico', 'M√©xico', 'Guadalajara', 'Jalisco', 'CDMX'], 'code': 'MEX'},
        'USA': {'keywords': ['USA', 'United States', 'U.S.A', 'California', 'Texas', 'Florida'], 'code': 'USA'},
        'Canada': {'keywords': ['Canada', 'Toronto', 'Vancouver', 'Montreal'], 'code': 'CAN'},
        'Spain': {'keywords': ['Spain', 'Espa√±a', 'Madrid', 'Barcelona', 'Sevilla'], 'code': 'ESP'},
        'Brazil': {'keywords': ['Brazil', 'Brasil', 'S√£o Paulo', 'Rio de Janeiro'], 'code': 'BRA'},
        'Argentina': {'keywords': ['Argentina', 'Buenos Aires'], 'code': 'ARG'},
        'Colombia': {'keywords': ['Colombia', 'Bogot√°', 'Medell√≠n'], 'code': 'COL'},
        'Chile': {'keywords': ['Chile', 'Santiago'], 'code': 'CHL'},
        'Peru': {'keywords': ['Peru', 'Per√∫', 'Lima'], 'code': 'PER'},
        'UK': {'keywords': ['United Kingdom', 'England', 'London', 'Scotland', 'UK'], 'code': 'GBR'},
        'Germany': {'keywords': ['Germany', 'Alemania', 'Berlin', 'Munich'], 'code': 'DEU'},
        'France': {'keywords': ['France', 'Francia', 'Paris'], 'code': 'FRA'},
        'Italy': {'keywords': ['Italy', 'Italia', 'Rome', 'Milan'], 'code': 'ITA'},
        'Netherlands': {'keywords': ['Netherlands', 'Amsterdam', 'Pa√≠ses Bajos'], 'code': 'NLD'},
        'Sweden': {'keywords': ['Sweden', 'Suecia', 'Stockholm'], 'code': 'SWE'},
        'Switzerland': {'keywords': ['Switzerland', 'Suiza', 'Geneva', 'Z√ºrich'], 'code': 'CHE'},
        'China': {'keywords': ['China', 'Beijing', 'Shanghai'], 'code': 'CHN'},
        'Japan': {'keywords': ['Japan', 'Jap√≥n', 'Tokyo'], 'code': 'JPN'},
        'South Korea': {'keywords': ['South Korea', 'Korea', 'Seoul'], 'code': 'KOR'},
        'India': {'keywords': ['India', 'New Delhi', 'Mumbai'], 'code': 'IND'},
        'Australia': {'keywords': ['Australia', 'Sydney', 'Melbourne'], 'code': 'AUS'},
    }

    # Contar colaboraciones por pa√≠s
    country_counts = {}

    for article in pubmed_data:
        countries_in_article = set()

        for affiliation in article.get('affiliations', []):
            if affiliation:
                for country, data in country_keywords.items():
                    for keyword in data['keywords']:
                        if keyword in affiliation:
                            countries_in_article.add(country)
                            break

        # Contar cada pa√≠s presente en el art√≠culo
        for country in countries_in_article:
            country_counts[country] = country_counts.get(country, 0) + 1

    if not country_counts:
        return None

    # Excluir M√©xico del mapa (es la sede del DCNT)
    if 'Mexico' in country_counts:
        del country_counts['Mexico']

    if not country_counts:
        return None

    # Preparar datos para el mapa
    countries = []
    codes = []
    counts = []

    for country, count in country_counts.items():
        countries.append(country)
        codes.append(country_keywords[country]['code'])
        counts.append(count)

    # Crear DataFrame
    df_map = pd.DataFrame({
        'Country': countries,
        'Code': codes,
        'Articles': counts
    })

    # Crear mapa choropleth
    fig = go.Figure(data=go.Choropleth(
        locations=df_map['Code'],
        z=df_map['Articles'],
        text=df_map['Country'],
        colorscale='Blues',
        autocolorscale=False,
        reversescale=False,
        marker_line_color='darkgray',
        marker_line_width=0.5,
        colorbar_title="Art√≠culos",
        hovertemplate='<b>%{text}</b><br>Art√≠culos: %{z}<extra></extra>'
    ))

    fig.update_layout(
        title_text='Mapa de Colaboraci√≥n Internacional del DCNT-UdeG (excluye M√©xico - sede)',
        geo=dict(
            showframe=False,
            showcoastlines=True,
            projection_type='natural earth'
        ),
        height=500
    )

    return fig, df_map


def filter_articulos_by_linea(lineas_data, linea_num):
    """Filtra art√≠culos que pertenecen a una l√≠nea espec√≠fica (principal o secundaria)"""
    if not lineas_data or 'articulos' not in lineas_data:
        return pd.DataFrame()

    articulos_filtrados = []

    for art in lineas_data['articulos']:
        # En el nuevo formato, todas las l√≠neas est√°n en 'lineas_principales'
        # La primera es la principal, las dem√°s con confianza='secundaria' son secundarias
        lineas = art['clasificacion'].get('lineas_principales', [])

        # Verificar si el art√≠culo pertenece a la l√≠nea
        linea_info = None
        tipo_clasificacion = None

        for idx, l in enumerate(lineas):
            if l['linea'] == linea_num:
                linea_info = l
                # La primera l√≠nea es siempre principal, las dem√°s son secundarias
                tipo_clasificacion = 'Principal' if idx == 0 else 'Secundaria'
                break

        if linea_info:
            # Obtener similitud (nuevo formato) o score_ml (formato antiguo)
            score = linea_info.get('similitud', linea_info.get('score_ml', linea_info.get('score_final', 0)))
            # Convertir similitud (0-1) a porcentaje si es necesario
            if score < 1.0:
                score = score * 100

            articulos_filtrados.append({
                'PMID': art['pmid'],
                'A√±o': art['a√±o'],
                'T√≠tulo': art['titulo'][:100] + '...' if len(art['titulo']) > 100 else art['titulo'],
                'Score ML': round(score, 1),
                'Confianza': linea_info['confianza'].capitalize(),
                'Tipo': tipo_clasificacion
            })

    return pd.DataFrame(articulos_filtrados)


# Interfaz principal
def main():
    # Encabezado con logo
    logo_path = Path(__file__).parent.parent / "assets" / "logo_dcnt.png"

    col_logo, col_title = st.columns([1, 5])

    with col_logo:
        if logo_path.exists():
            st.image(str(logo_path), width=100)

    with col_title:
        st.markdown("""
        <div style='text-align: left;'>
            <h1 style='color: #1f77b4; margin-bottom: 0;'>Dashboard de Productividad Cient√≠fica</h1>
            <h2 style='color: #2c3e50; margin-top: 0;'>Doctorado en Ciencias de la Nutrici√≥n Traslacional</h2>
            <p style='color: #666; font-size: 1.1rem;'>Universidad de Guadalajara ‚Ä¢ 2019-2025</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # Sidebar - Toggle de tema
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuraci√≥n")

        # Toggle para cambiar entre modo claro y oscuro
        theme_option = st.radio(
            "Tema de visualizaci√≥n:",
            options=['‚òÄÔ∏è Modo Claro', 'üåô Modo Oscuro'],
            index=0 if st.session_state.theme == 'light' else 1,
            key='theme_selector'
        )

        # Actualizar el tema si cambi√≥
        new_theme = 'dark' if 'üåô' in theme_option else 'light'
        if new_theme != st.session_state.theme:
            st.session_state.theme = new_theme
            st.rerun()

        st.markdown("---")

    # Cargar datos
    publications_df, ods_data, pronaces_data, themes_data, lineas_data = load_data()
    pubmed_data = load_pubmed_metadata()

    # Usar todos los a√±os sin filtros
    selected_years = sorted(publications_df['a√±o'].unique())
    filtered_df = publications_df

    # SECCI√ìN 0: Contexto y Pertinencia Estrat√©gica
    st.markdown('<div class="section-header">üéØ Contexto y Pertinencia Estrat√©gica</div>', unsafe_allow_html=True)

    st.markdown("""
    El **Doctorado en Ciencias de la Nutrici√≥n Traslacional (DCNT-UdeG)** responde directamente a las crisis
    nutricionales m√°s urgentes de M√©xico. Este dashboard presenta la evidencia de productividad cient√≠fica
    que demuestra la **contribuci√≥n del programa a prioridades nacionales** (PRONACES), **compromisos internacionales** (ODS),
    y **problem√°ticas regionales cr√≠ticas**.
    """)

    # M√©tricas clave de contexto
    st.markdown("### üö® Crisis Epidemiol√≥gica que Justifica el Programa")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="Sobrepeso/Obesidad en Adultos",
            value=f"{EPIDEMIOLOGIA_MEXICO['sobrepeso_obesidad_adultos']['valor']}%",
            delta="75.2% de adultos (M√©xico)",
            delta_color="inverse"
        )
        st.caption("ENSANUT 2022")

    with col2:
        st.metric(
            label="Diabetes en Adultos",
            value=f"{EPIDEMIOLOGIA_MEXICO['diabetes_adultos']['valor']}%",
            delta="14.6 millones de personas",
            delta_color="inverse"
        )
        st.caption("ENSANUT 2022")

    with col3:
        st.metric(
            label="Muertes por Obesidad en Jalisco",
            value=f"{EPIDEMIOLOGIA_JALISCO['muertes_obesidad']['asociadas_obesidad']:,}",
            delta="30% de muertes anuales",
            delta_color="inverse"
        )
        st.caption("Secretar√≠a de Salud Jalisco")

    with col4:
        st.metric(
            label="Desnutrici√≥n Infantil Jalisco",
            value="2do lugar",
            delta="+88% (2021-2023)",
            delta_color="inverse"
        )
        st.caption("Vigilancia Epidemiol√≥gica")

    # Alerta destacada
    st.error("""
    **‚ö†Ô∏è Situaci√≥n Cr√≠tica en Jalisco:**
    - **6,284 casos** de desnutrici√≥n infantil en 2023 (incremento de 88% desde 2021)
    - **56.5%** de diab√©ticos hospitalizados **NO reciben atenci√≥n nutricional**
    - **1,176,459 personas** con carencia de acceso a alimentaci√≥n en Jalisco
    - Proyecci√≥n nacional: **88% con sobrepeso/obesidad** para 2050 sin intervenciones efectivas
    """)

    # Pertinencia del enfoque traslacional
    st.info("""
    **üí° El Enfoque Traslacional del DCNT-UdeG:**

    El programa es √∫nico porque forma investigadores capaces de trabajar en todo el continuum de la investigaci√≥n traslacional:

    - **T0 (Investigaci√≥n B√°sica)**: Mecanismos moleculares, interacciones gen-dieta, biomarcadores
    - **T1-T2 (Traslaci√≥n Cl√≠nica)**: Estudios en humanos, protocolos de atenci√≥n nutricional basados en evidencia
    - **T3-T4 (Traslaci√≥n Poblacional)**: Implementaci√≥n en sistemas de salud, pol√≠ticas p√∫blicas escalables

    Este es el paradigma cient√≠fico del siglo XXI que M√©xico necesita para convertir conocimiento b√°sico en **soluciones efectivas** contra la doble carga de malnutrici√≥n.

    *Fuente: Surkis A, et al. (2016). "Classifying publications from the clinical and translational science award program along the translational research spectrum: a machine learning approach". Journal of Translational Medicine, 14:235. [PMID: 27492440](https://pubmed.ncbi.nlm.nih.gov/27492440/) | DOI: [10.1186/s12967-016-0992-8](https://doi.org/10.1186/s12967-016-0992-8)*
    """)

    st.markdown("---")

    # SECCI√ìN 1: Panorama General
    st.markdown('<div class="section-header">üìà Panorama General de Productividad Cient√≠fica</div>', unsafe_allow_html=True)

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="Total de Publicaciones",
            value=len(filtered_df),
            delta=f"{len(publications_df)} total"
        )

    with col2:
        st.metric(
            label="A√±os Analizados",
            value=f"{filtered_df['a√±o'].min()} - {filtered_df['a√±o'].max()}",
            delta=f"{len(filtered_df['a√±o'].unique())} a√±os"
        )

    with col3:
        st.metric(
            label="Revistas √önicas",
            value=filtered_df['revista'].nunique()
        )

    with col4:
        st.metric(
            label="Promedio Anual",
            value=f"{len(filtered_df) / len(selected_years):.1f}"
        )

    # Gr√°fica de evoluci√≥n
    st.plotly_chart(create_year_evolution_chart(filtered_df), use_container_width=True)

    # SECCI√ìN 2: Contribuci√≥n a ODS
    st.markdown('<div class="section-header">üåç Contribuci√≥n a Objetivos de Desarrollo Sostenible</div>', unsafe_allow_html=True)

    if ods_data:
        # Obtener estad√≠sticas
        ods_stats = get_ods_stats(ods_data)
        total_ods_articles = len(ods_data)

        # Resumen visual en m√©tricas
        st.markdown("### üìä Alineaci√≥n con Agenda 2030")

        # Primera fila de ODS principales
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            count_2 = ods_stats.get(2, 0)
            st.metric("üåæ ODS 2: Hambre Cero", f"{count_2} art√≠culos", f"{count_2/total_ods_articles*100:.1f}%")

        with col2:
            count_3 = ods_stats.get(3, 0)
            st.metric("‚ù§Ô∏è ODS 3: Salud y Bienestar", f"{count_3} art√≠culos", f"{count_3/total_ods_articles*100:.1f}%")

        with col3:
            count_10 = ods_stats.get(10, 0)
            st.metric("‚öñÔ∏è ODS 10: Reducir Desigualdades", f"{count_10} art√≠culos", f"{count_10/total_ods_articles*100:.1f}%")

        with col4:
            count_12 = ods_stats.get(12, 0)
            st.metric("‚ôªÔ∏è ODS 12: Producci√≥n y Consumo", f"{count_12} art√≠culos", f"{count_12/total_ods_articles*100:.1f}%")

        # Segunda fila de ODS adicionales - ahora con 3 columnas
        col5, col6, col7 = st.columns(3)

        with col5:
            count_1 = ods_stats.get(1, 0)
            st.metric("üèöÔ∏è ODS 1: Fin de la Pobreza", f"{count_1} art√≠culos", f"{count_1/total_ods_articles*100:.1f}%" if count_1 > 0 else "0%")

        with col6:
            count_5 = ods_stats.get(5, 0)
            st.metric("üë• ODS 5: Igualdad de G√©nero", f"{count_5} art√≠culos", f"{count_5/total_ods_articles*100:.1f}%" if count_5 > 0 else "0%")

        with col7:
            # Calcular el total de ODS abordados
            num_ods = len([v for v in ods_stats.values() if v > 0])
            st.metric("üéØ Total ODS Abordados", f"{num_ods} ODS", f"{num_ods/17*100:.0f}% de la Agenda")

        st.markdown("---")

        # Nota explicativa sobre la metodolog√≠a
        with st.expander("‚ÑπÔ∏è Metodolog√≠a de Clasificaci√≥n de ODS", expanded=False):
            st.markdown("""
            ### ü§ñ Clasificaci√≥n Autom√°tica con Embeddings

            Los art√≠culos fueron clasificados autom√°ticamente usando **sentence-transformers** con el modelo `all-MiniLM-L6-v2`.

            **Metadata utilizada para clasificaci√≥n:**
            - ‚úÖ **T√≠tulo completo** del art√≠culo
            - ‚úÖ **Abstract** (resumen cient√≠fico completo)
            - ‚úÖ **T√©rminos MeSH** (vocabulario controlado de PubMed)
            - ‚úÖ **Keywords** (palabras clave de autores)

            **Proceso:**
            1. Se generan embeddings (representaciones vectoriales) de cada art√≠culo usando toda su metadata
            2. Se generan embeddings de las descripciones detalladas de cada ODS
            3. Se calcula la **similitud de coseno** entre cada art√≠culo y cada ODS
            4. Se asignan ODS principales (similitud ‚â• 0.45) y secundarios (similitud ‚â• 0.35)

            **ODS clasificados:** 7 ODS relevantes para investigaci√≥n en nutrici√≥n traslacional (ODS 1, 2, 3, 5, 10, 12, 13)
            """)

        st.markdown("---")

        # Gr√°fica de distribuci√≥n
        col_graph, col_info = st.columns([1, 1])

        with col_graph:
            fig_ods = create_ods_distribution(ods_data)
            if fig_ods:
                st.plotly_chart(fig_ods, use_container_width=True)

        with col_info:
            st.info("""
            **Meta 2030 de la Agenda Global:**

            Los 17 Objetivos de Desarrollo Sostenible (ODS) son el plan maestro de la ONU para un futuro sostenible.

            El DCNT-UdeG contribuye directamente a m√∫ltiples ODS prioritarios, abordando desaf√≠os interconectados de nutrici√≥n, salud, educaci√≥n, equidad y desarrollo sostenible.
            """)

        st.markdown("---")

        # Explorador interactivo de art√≠culos por ODS
        st.markdown("### üìö Explorador de Art√≠culos por ODS")

        st.markdown("""
        Selecciona un ODS para ver todos los art√≠culos clasificados (principales y secundarios).
        """)

        # Selector de ODS
        ods_options = {
            1: "ODS 1: Fin de la Pobreza",
            2: "ODS 2: Hambre Cero",
            3: "ODS 3: Salud y Bienestar",
            5: "ODS 5: Igualdad de G√©nero",
            10: "ODS 10: Reducci√≥n de Desigualdades",
            12: "ODS 12: Producci√≥n y Consumo Responsables",
            13: "ODS 13: Acci√≥n por el Clima"
        }

        selected_ods = st.selectbox(
            "Selecciona un ODS:",
            options=list(ods_options.keys()),
            format_func=lambda x: ods_options[x],
            index=2  # ODS 3 por defecto (el m√°s frecuente)
        )

        if selected_ods:
            # Filtrar art√≠culos del ODS seleccionado
            articulos_principales = []
            articulos_secundarios = []

            for articulo in ods_data:
                # Verificar ODS principales
                for ods_p in articulo.get('ods_principales', []):
                    if ods_p.get('numero') == selected_ods:
                        articulos_principales.append({
                            't√≠tulo': articulo.get('titulo', ''),
                            'a√±o': articulo.get('a√±o', 0),
                            'revista': articulo.get('revista', ''),
                            'doi': articulo.get('doi', ''),
                            'similitud': ods_p.get('similitud', 0),
                            'confianza': ods_p.get('confianza', ''),
                            'tipo': 'Principal'
                        })
                        break

                # Verificar ODS secundarios
                for ods_s in articulo.get('ods_secundarios', []):
                    if ods_s.get('numero') == selected_ods:
                        articulos_secundarios.append({
                            't√≠tulo': articulo.get('titulo', ''),
                            'a√±o': articulo.get('a√±o', 0),
                            'revista': articulo.get('revista', ''),
                            'doi': articulo.get('doi', ''),
                            'similitud': ods_s.get('similitud', 0),
                            'confianza': ods_s.get('confianza', ''),
                            'tipo': 'Secundario'
                        })
                        break

            total_articulos = len(articulos_principales) + len(articulos_secundarios)

            # Mostrar estad√≠sticas
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("üìä Total de art√≠culos", total_articulos)
            with col_stat2:
                st.metric("üéØ ODS Principal", len(articulos_principales))
            with col_stat3:
                st.metric("üîó ODS Secundario", len(articulos_secundarios))

            # Mostrar art√≠culos
            if total_articulos > 0:
                st.markdown(f"#### Art√≠culos clasificados en {ods_options[selected_ods]}")

                # Combinar y crear DataFrame
                todos_articulos = articulos_principales + articulos_secundarios
                df_ods_articulos = pd.DataFrame(todos_articulos)

                # Ordenar por tipo (principales primero) y luego por similitud
                df_ods_articulos['tipo_orden'] = df_ods_articulos['tipo'].map({'Principal': 0, 'Secundario': 1})
                df_ods_articulos = df_ods_articulos.sort_values(['tipo_orden', 'similitud'], ascending=[True, False])
                df_ods_articulos = df_ods_articulos.drop('tipo_orden', axis=1)

                # Renombrar columnas para mejor visualizaci√≥n
                df_ods_articulos = df_ods_articulos.rename(columns={
                    't√≠tulo': 'T√≠tulo',
                    'a√±o': 'A√±o',
                    'revista': 'Revista',
                    'doi': 'DOI',
                    'similitud': 'Similitud',
                    'confianza': 'Confianza',
                    'tipo': 'Clasificaci√≥n'
                })

                # Mostrar tabla
                st.dataframe(
                    df_ods_articulos,
                    use_container_width=True,
                    height=400,
                    column_config={
                        "Similitud": st.column_config.ProgressColumn(
                            "Similitud",
                            help="Similitud con el ODS (0-1)",
                            format="%.3f",
                            min_value=0,
                            max_value=1,
                        ),
                        "Confianza": st.column_config.TextColumn(
                            "Confianza",
                            help="Nivel de confianza de la clasificaci√≥n",
                        ),
                        "Clasificaci√≥n": st.column_config.TextColumn(
                            "Clasificaci√≥n",
                            help="Principal o Secundario",
                        )
                    }
                )

                # Bot√≥n de descarga
                csv = df_ods_articulos.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label=f"‚¨áÔ∏è Descargar art√≠culos de {ods_options[selected_ods]} (CSV)",
                    data=csv,
                    file_name=f"articulos_ods_{selected_ods}.csv",
                    mime="text/csv",
                )

                # Distribuci√≥n de confianza
                st.markdown("##### Distribuci√≥n de Confianza")
                confianza_counts = df_ods_articulos['Confianza'].value_counts()

                col_conf1, col_conf2, col_conf3, col_conf4 = st.columns(4)
                with col_conf1:
                    st.metric("üü¢ Alta", confianza_counts.get('alta', 0))
                with col_conf2:
                    st.metric("üü° Media", confianza_counts.get('media', 0))
                with col_conf3:
                    st.metric("üü† Baja", confianza_counts.get('baja', 0))
                with col_conf4:
                    st.metric("üî¥ Tentativa", confianza_counts.get('tentativa', 0))

            else:
                st.info(f"No hay art√≠culos clasificados en {ods_options[selected_ods]}")


    else:
        st.warning("‚ö†Ô∏è Ejecuta primero el script de clasificaci√≥n paralela para generar los datos de ODS")
        st.code("python src/classify_parallel.py", language="bash")

    # SECCI√ìN 3: Alineaci√≥n con PRONACES
    st.markdown('<div class="section-header">üá≤üáΩ Alineaci√≥n con PRONACES - Prioridades Nacionales</div>', unsafe_allow_html=True)

    # Contexto PRONACES
    st.info(f"""
    **Programas Nacionales Estrat√©gicos de Ciencia y Tecnolog√≠a (PRONACES)**

    La pol√≠tica cient√≠fica m√°s importante de M√©xico para 2023-2025:
    - **Inversi√≥n:** {PRONACES_CONTEXTO['inversion_total']['monto']} en {PRONACES_CONTEXTO['inversion_total']['proyectos']} proyectos
    - **Alcance:** {PRONACES_CONTEXTO['inversion_total']['personas']} personas en {PRONACES_CONTEXTO['inversion_total']['instituciones']} instituciones
    - **Modelo:** Transdisciplinario que integra academia-gobierno-comunidad con acceso abierto
    """)

    if pronaces_data:
        # Calcular estad√≠sticas de PRONACES
        pronace_counts = {
            "SALUD": 0,
            "SOBERANIA_ALIMENTARIA": 0,
            "SISTEMAS_ALIMENTARIOS": 0
        }

        for article in pronaces_data:
            for pron in article.get('pronaces_principales', []):
                codigo = pron.get('codigo', '')
                if codigo in pronace_counts:
                    pronace_counts[codigo] += 1

        total_clasificados = sum(pronace_counts.values())

        # Layout mejorado
        st.markdown("### üìä Distribuci√≥n de Publicaciones por PRONACE")

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(
                "Total Clasificado",
                total_clasificados,
                delta=f"{(total_clasificados/len(publications_df)*100):.1f}% del total"
            )
        with col2:
            st.metric(
                "üè• Salud",
                pronace_counts["SALUD"],
                delta=f"{(pronace_counts['SALUD']/total_clasificados*100):.1f}%"
            )
        with col3:
            st.metric(
                "üåæ Soberan√≠a Alimentaria",
                pronace_counts["SOBERANIA_ALIMENTARIA"],
                delta=f"{(pronace_counts['SOBERANIA_ALIMENTARIA']/total_clasificados*100):.1f}%"
            )
        with col4:
            st.metric(
                "‚ôªÔ∏è Sistemas Alimentarios",
                pronace_counts["SISTEMAS_ALIMENTARIOS"],
                delta=f"{(pronace_counts['SISTEMAS_ALIMENTARIOS']/total_clasificados*100):.1f}%"
            )

        st.markdown("---")

        # Gr√°fico de distribuci√≥n
        col_left, col_right = st.columns([1, 1])

        with col_left:
            # Gr√°fico de barras horizontales
            pronace_names = {
                "SALUD": "üè• PRONACE Salud",
                "SOBERANIA_ALIMENTARIA": "üåæ PRONACE Soberan√≠a Alimentaria",
                "SISTEMAS_ALIMENTARIOS": "‚ôªÔ∏è Sistemas Alimentarios Sostenibles"
            }

            fig_dist = go.Figure(data=[
                go.Bar(
                    y=[pronace_names[k] for k in pronace_counts.keys()],
                    x=list(pronace_counts.values()),
                    orientation='h',
                    text=list(pronace_counts.values()),
                    textposition='auto',
                    marker=dict(
                        color=['#FF6B6B', '#4ECDC4', '#45B7D1'],
                        line=dict(color='white', width=2)
                    )
                )
            ])

            fig_dist.update_layout(
                title='Publicaciones del DCNT por PRONACE',
                xaxis_title='N√∫mero de Publicaciones',
                yaxis_title='',
                height=300,
                showlegend=False
            )

            st.plotly_chart(fig_dist, use_container_width=True)

        with col_right:
            # Heatmap temporal
            fig_pronaces = create_pronaces_heatmap(pronaces_data, filtered_df)
            if fig_pronaces:
                st.plotly_chart(fig_pronaces, use_container_width=True)

        st.markdown("---")

        # Secci√≥n mejorada: Relevancia para el DCNT
        st.markdown("### üéØ Relevancia de los PRONACES para el DCNT-UdeG")

        # PRONACE SALUD
        with st.expander("üè• PRONACE SALUD - Cobertura Principal del DCNT", expanded=True):
            col_a, col_b = st.columns([1, 1])

            with col_a:
                st.markdown(f"""
                **üìä Alineaci√≥n del DCNT:**
                - **{pronace_counts['SALUD']} publicaciones** ({(pronace_counts['SALUD']/total_clasificados*100):.1f}% del total)
                - Principal √°rea de contribuci√≥n del programa
                - Aborda crisis nacional de ENT

                **üéØ √Åreas Prioritarias PRONACE:**
                - Enfermedades Cr√≥nicas no Transmisibles
                - Alimentaci√≥n y Salud Integral Comunitaria
                - Medicina de Sistemas y Determinantes Moleculares
                - Ciencia de Datos Aplicada a Salud
                """)

            with col_b:
                st.markdown(f"""
                **üí° Contribuci√≥n Espec√≠fica del DCNT:**

                **L√≠nea 1 (Gen√≥mica Nutricional):**
                - Medicina de sistemas y biomarcadores
                - Determinantes moleculares de ENT
                - Nutrigen√©tica y nutrigen√≥mica

                **L√≠nea 2 (Salud P√∫blica):**
                - Intervenciones comunitarias escalables
                - Evaluaci√≥n de pol√≠ticas de salud
                - Investigaci√≥n traslacional poblacional

                **L√≠nea 3 (Alimentaci√≥n y Nutrici√≥n):**
                - Terapia nutricional en ENT
                - Patrones alimentarios saludables
                - Prevenci√≥n de obesidad y diabetes
                """)

            st.info(f"""
            üí∞ **Financiamiento:** {PRONACES_CONTEXTO['PRONACE_SALUD']['financiamiento']}

            üî¨ **Competencia del DCNT:** Los graduados est√°n preparados para liderar proyectos PRONAII en
            prevenci√≥n y manejo de ENT, con expertise en gen√≥mica nutricional, intervenciones poblacionales
            y medicina de precisi√≥n aplicada a nutrici√≥n.
            """)

        # PRONACE SOBERAN√çA ALIMENTARIA
        with st.expander("üåæ PRONACE SOBERAN√çA ALIMENTARIA - Segunda √Årea de Impacto"):
            col_a, col_b = st.columns([1, 1])

            with col_a:
                st.markdown(f"""
                **üìä Alineaci√≥n del DCNT:**
                - **{pronace_counts['SOBERANIA_ALIMENTARIA']} publicaciones** ({(pronace_counts['SOBERANIA_ALIMENTARIA']/total_clasificados*100):.1f}% del total)
                - Enfoque en malnutrici√≥n y seguridad alimentaria
                - Alimentos funcionales y tradicionales

                **üéØ Demandas Prioritarias PRONACE:**
                - Alimentaci√≥n saludable y culturalmente adecuada
                - Alimentos funcionales
                - Calidad nutrimental ma√≠z-tortilla
                - Educaci√≥n para alimentaci√≥n saludable
                - Circuitos regionales de alimentos
                """)

            with col_b:
                st.markdown(f"""
                **üí° Contribuci√≥n Espec√≠fica del DCNT:**

                **L√≠nea 2 (Salud P√∫blica):**
                - Educaci√≥n nutricional comunitaria
                - Evaluaci√≥n de programas alimentarios
                - Intervenciones en poblaciones vulnerables

                **L√≠nea 3 (Alimentaci√≥n y Nutrici√≥n):**
                - Ciencias de alimentos y alimentos funcionales
                - Calidad nutrimental de alimentos tradicionales
                - Desarrollo de productos nutricionales
                - Sistemas alimentarios locales
                """)

            st.success(f"""
            üå± **Alcance Nacional:** {PRONACES_CONTEXTO['PRONACE_SOBERANIA_ALIMENTARIA']['pronaii_activos']} PRONAII activos en
            {PRONACES_CONTEXTO['PRONACE_SOBERANIA_ALIMENTARIA']['localidades']} localidades con
            {PRONACES_CONTEXTO['PRONACE_SOBERANIA_ALIMENTARIA']['organizaciones_comunitarias']} organizaciones comunitarias.

            üéì **Formaci√≥n DCNT:** Los estudiantes desarrollan competencias en investigaci√≥n participativa,
            valoraci√≥n de alimentos tradicionales, y dise√±o de intervenciones nutricionales culturalmente apropiadas.
            """)

        # SISTEMAS ALIMENTARIOS
        with st.expander("‚ôªÔ∏è SISTEMAS ALIMENTARIOS SOSTENIBLES - √Årea Emergente"):
            col_a, col_b = st.columns([1, 1])

            with col_a:
                st.markdown(f"""
                **üìä Alineaci√≥n del DCNT:**
                - **{pronace_counts['SISTEMAS_ALIMENTARIOS']} publicaciones** ({(pronace_counts['SISTEMAS_ALIMENTARIOS']/total_clasificados*100):.1f}% del total)
                - Consumo responsable y sostenibilidad
                - Impacto de alimentos ultraprocesados

                **üéØ Temas de Investigaci√≥n:**
                - Alimentos ultraprocesados y bebidas azucaradas
                - Patrones diet√©ticos sostenibles
                - Etiquetado frontal de alimentos
                - Ambientes alimentarios saludables
                - Transici√≥n nutricional
                """)

            with col_b:
                st.markdown(f"""
                **üí° Contribuci√≥n Espec√≠fica del DCNT:**

                **Enfoque Transdisciplinario:**
                - An√°lisis de sistemas alimentarios complejos
                - Impacto ambiental de patrones diet√©ticos
                - Pol√≠ticas p√∫blicas de alimentaci√≥n
                - Innovaci√≥n en alimentos funcionales

                **Investigaci√≥n Traslacional:**
                - Evaluaci√≥n de intervenciones de etiquetado
                - Estudios de consumo alimentario
                - An√°lisis de ambientes obesog√©nicos
                """)

            st.warning("""
            ‚ö†Ô∏è **√Årea en Crecimiento:** Aunque actualmente representa {:.1f}% de las publicaciones,
            es un √°rea estrat√©gica emergente que vincula salud p√∫blica, sostenibilidad ambiental y
            pol√≠ticas alimentarias - competencias clave para el futuro de la nutrici√≥n en M√©xico.
            """.format(pronace_counts['SISTEMAS_ALIMENTARIOS']/total_clasificados*100))

        st.markdown("---")

        # Nota de metodolog√≠a
        with st.expander("‚ÑπÔ∏è Metodolog√≠a de Clasificaci√≥n", expanded=False):
            st.markdown("""
            **Clasificaci√≥n Autom√°tica con Embeddings:**

            Los art√≠culos del DCNT fueron clasificados en PRONACES utilizando **embeddings sem√°nticos**
            (modelo all-MiniLM-L6-v2) con similitud de coseno.

            **Proceso:**
            1. Se generan embeddings (representaciones vectoriales) de cada art√≠culo usando toda su metadata
            2. Se generan embeddings de las descripciones detalladas de cada PRONACE
            3. Se calcula la **similitud de coseno** entre cada art√≠culo y cada PRONACE
            4. Se asignan PRONACES principales (similitud ‚â• 0.40) y secundarios (similitud ‚â• 0.30)

            **PRONACES clasificados:** 3 programas m√°s relevantes para investigaci√≥n en nutrici√≥n traslacional:
            - PRONACE Salud
            - PRONACE Soberan√≠a Alimentaria
            - Sistemas Alimentarios Sostenibles
            """)

        st.markdown("---")

        # Explorador interactivo de PRONACES
        st.markdown("### üîç Explorador de Art√≠culos por PRONACE")

        # Preparar opciones
        pronace_options = {
            "SALUD": "üè• PRONACE Salud",
            "SOBERANIA_ALIMENTARIA": "üåæ PRONACE Soberan√≠a Alimentaria",
            "SISTEMAS_ALIMENTARIOS": "‚ôªÔ∏è Sistemas Alimentarios Sostenibles"
        }

        selected_pronace = st.selectbox(
            "Selecciona un PRONACE:",
            options=list(pronace_options.keys()),
            format_func=lambda x: pronace_options[x],
            index=0  # SALUD por defecto
        )

        # Filtrar art√≠culos del PRONACE seleccionado
        pronace_articles = []
        for article in pronaces_data:
            # Verificar si est√° en principales
            for pron in article.get('pronaces_principales', []):
                if pron['codigo'] == selected_pronace:
                    pronace_articles.append({
                        'tipo': 'Principal',
                        **article
                    })
                    break
            else:
                # Verificar si est√° en secundarios
                for pron in article.get('pronaces_secundarios', []):
                    if pron['codigo'] == selected_pronace:
                        pronace_articles.append({
                            'tipo': 'Secundario',
                            **article
                        })
                        break

        # Mostrar m√©tricas
        st.markdown(f"#### Art√≠culos clasificados en {pronace_options[selected_pronace]}")

        principales_count = sum(1 for a in pronace_articles if a.get('tipo') == 'Principal')
        secundarios_count = sum(1 for a in pronace_articles if a.get('tipo') == 'Secundario')

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total", len(pronace_articles))
        with col2:
            st.metric("Principales", principales_count)
        with col3:
            st.metric("Secundarios", secundarios_count)

        if pronace_articles:
            # Preparar dataframe
            df_pronace = pd.DataFrame([
                {
                    'A√±o': art['a√±o'],
                    'T√≠tulo': art['titulo'],
                    'Revista': art['revista'],
                    'Clasificaci√≥n': art['tipo'],
                    'Similitud': next((p['similitud'] for p in art.get('pronaces_principales', []) if p['codigo'] == selected_pronace),
                                    next((p['similitud'] for p in art.get('pronaces_secundarios', []) if p['codigo'] == selected_pronace), 0)),
                    'Confianza': next((p['confianza'] for p in art.get('pronaces_principales', []) if p['codigo'] == selected_pronace),
                                    next((p['confianza'] for p in art.get('pronaces_secundarios', []) if p['codigo'] == selected_pronace), '')),
                    'DOI': art.get('doi', ''),
                    'PMID': art.get('pmid', '')
                }
                for art in pronace_articles
            ])

            # Ordenar por similitud
            df_pronace = df_pronace.sort_values('Similitud', ascending=False)

            st.dataframe(
                df_pronace,
                use_container_width=True,
                height=400
            )

            # Bot√≥n de descarga
            csv = df_pronace.to_csv(index=False).encode('utf-8')
            st.download_button(
                label=f"‚¨áÔ∏è Descargar art√≠culos de {pronace_options[selected_pronace]} (CSV)",
                data=csv,
                file_name=f'pronace_{selected_pronace.lower()}_articulos.csv',
                mime='text/csv'
            )

        else:
            st.info(f"No hay art√≠culos clasificados en {pronace_options[selected_pronace]}")

        st.markdown("---")

        st.success("""
        ‚úÖ **Alta Pertinencia Demostrada:** El DCNT-UdeG forma recursos humanos especializados
        para liderar o participar en futuros PRONAII, con competencias espec√≠ficas en investigaci√≥n
        traslacional, vinculaci√≥n con gobierno/comunidad, y trabajo multidisciplinario.
        """)

    else:
        st.warning("‚ö†Ô∏è Ejecuta primero el script de clasificaci√≥n para generar los datos de PRONACES")

    # SECCI√ìN 4: An√°lisis Tem√°tico con T√©rminos MeSH y Keywords
    st.markdown('<div class="section-header">üî¨ An√°lisis Tem√°tico de la Investigaci√≥n (MeSH + Keywords)</div>', unsafe_allow_html=True)

    if pubmed_data:
        st.markdown("""
        An√°lisis tem√°tico enriquecido combinando:
        - **T√©rminos MeSH**: Vocabulario controlado asignado por expertos del NLM (National Library of Medicine)
        - **Keywords**: Palabras clave espec√≠ficas proporcionadas por los autores de cada art√≠culo

        Esta combinaci√≥n proporciona una visi√≥n m√°s completa: los t√©rminos MeSH garantizan estandarizaci√≥n,
        mientras que las keywords capturan la especificidad y terminolog√≠a actual de cada investigaci√≥n.
        """)

        # Estad√≠sticas generales
        total_articles = len(pubmed_data)
        articles_with_mesh = sum(1 for a in pubmed_data if a.get('mesh_terms', []))
        articles_with_keywords = sum(1 for a in pubmed_data if a.get('keywords', []))

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìö Total de Art√≠culos", total_articles)
        with col2:
            st.metric("üè∑Ô∏è Con T√©rminos MeSH", f"{articles_with_mesh} ({articles_with_mesh/total_articles*100:.1f}%)")
        with col3:
            st.metric("üîë Con Keywords", f"{articles_with_keywords} ({articles_with_keywords/total_articles*100:.1f}%)")

        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üéØ T√©rminos Combinados",
            "üìä MeSH",
            "üîë Keywords",
            "‚öñÔ∏è Comparaci√≥n",
            "üî• Co-ocurrencia"
        ])

        with tab1:
            st.markdown("### T√©rminos M√°s Frecuentes (MeSH + Keywords)")
            st.info("""
            Esta visualizaci√≥n combina t√©rminos MeSH y keywords, mostrando la fuente de cada t√©rmino con colores:
            - üîµ **Azul**: Solo MeSH (estandarizado)
            - üî¥ **Rosa**: Solo Keywords (espec√≠fico de autores)
            - üü† **Naranja**: Aparece en ambos (validaci√≥n cruzada)
            """)
            fig_combined = create_combined_terms_distribution(pubmed_data, top_n=30)
            if fig_combined:
                st.plotly_chart(fig_combined, use_container_width=True)
                st.caption("""
                üí° **Interpretaci√≥n:** Los t√©rminos en naranja (aparecen en ambas fuentes) indican temas
                bien establecidos y ampliamente reconocidos. Los t√©rminos √∫nicos de keywords revelan
                terminolog√≠a emergente o espec√≠fica del campo.
                """)

        with tab2:
            st.markdown("### Distribuci√≥n de T√©rminos MeSH")
            st.info("""
            **T√©rminos MeSH (Medical Subject Headings)**:
            - Vocabulario controlado de biomedicina
            - Asignados por indexadores expertos de PubMed
            - Garantizan consistencia y comparabilidad internacional
            """)
            fig_mesh_dist = create_mesh_distribution(pubmed_data, top_n=25)
            if fig_mesh_dist:
                st.plotly_chart(fig_mesh_dist, use_container_width=True)
                st.caption("""
                üí° **Interpretaci√≥n:** T√©rminos estandarizados que permiten comparar la investigaci√≥n
                del DCNT con otros programas a nivel internacional.
                """)

        with tab3:
            st.markdown("### Distribuci√≥n de Keywords (Palabras Clave de Autores)")
            st.info("""
            **Keywords de Autores**:
            - T√©rminos espec√≠ficos elegidos por los investigadores
            - Reflejan la terminolog√≠a actual del campo
            - Capturan conceptos emergentes y especificidad metodol√≥gica
            """)
            fig_keywords_dist = create_keywords_distribution(pubmed_data, top_n=25)
            if fig_keywords_dist:
                st.plotly_chart(fig_keywords_dist, use_container_width=True)
                st.caption("""
                üí° **Interpretaci√≥n:** Las keywords revelan los t√©rminos espec√≠ficos que los investigadores
                del DCNT consideran m√°s representativos de su trabajo, incluyendo terminolog√≠a t√©cnica
                y conceptos emergentes no siempre capturados por MeSH.
                """)

        with tab4:
            st.markdown("### Cobertura: MeSH vs Keywords")
            st.info("""
            Comparaci√≥n de la cobertura de t√©rminos en los art√≠culos del DCNT.
            Idealmente, los art√≠culos deben tener tanto t√©rminos MeSH (estandarizaci√≥n) como keywords (especificidad).
            """)
            fig_comparison = create_mesh_vs_keywords_comparison(pubmed_data)
            if fig_comparison:
                st.plotly_chart(fig_comparison, use_container_width=True)
                st.caption("""
                üí° **Interpretaci√≥n:** Los art√≠culos con ambos tipos de t√©rminos tienen la mejor
                visibilidad y permiten an√°lisis m√°s completos. Los art√≠culos sin t√©rminos pueden
                requerir actualizaci√≥n de metadata.
                """)

        with tab5:
            st.markdown("### Matriz de Co-ocurrencia de T√©rminos MeSH")
            fig_mesh_cooccurrence = create_mesh_cooccurrence(pubmed_data, top_n=15)
            if fig_mesh_cooccurrence:
                st.plotly_chart(fig_mesh_cooccurrence, use_container_width=True)
                st.caption("""
                üí° **Interpretaci√≥n:** Esta matriz muestra cu√°ntas veces dos t√©rminos MeSH aparecen juntos.
                Valores altos revelan las intersecciones tem√°ticas m√°s frecuentes en la investigaci√≥n del DCNT.
                """)

                # An√°lisis adicional de conexiones fuertes
                st.markdown("#### üîó Conexiones Interdisciplinarias Destacadas")

                top_mesh_connections = get_top_mesh_connections(pubmed_data, top_n=10)

                if top_mesh_connections:
                    st.markdown("**Top 10 combinaciones de t√©rminos MeSH m√°s frecuentes:**")
                    for (term1, term2), count in top_mesh_connections:
                        st.write(f"- **{term1}** ‚Üî **{term2}**: {count} publicaciones")

                    st.info("""
                    Estas conexiones muestran el **enfoque interdisciplinario** del programa, donde se integran
                    m√∫ltiples √°reas de conocimiento para abordar problemas complejos de nutrici√≥n y salud.
                    """)
    else:
        st.warning("‚ö†Ô∏è No hay datos de PubMed disponibles para an√°lisis tem√°tico")

    # ========================================================================
    # NUEVAS SUBSECCIONES: AN√ÅLISIS ENRIQUECIDO CON METADATA DE PUBMED
    # ========================================================================

    if pubmed_data:
        st.markdown("---")
        st.markdown('<div class="section-header">üìä An√°lisis Enriquecido con Metadata de PubMed</div>', unsafe_allow_html=True)

        st.markdown("""
        An√°lisis enriquecido con metadata completa de **PubMed/MEDLINE**, incluyendo t√©rminos MeSH,
        citaciones, tipos de evidencia, financiamiento y colaboraciones internacionales.
        """)

        # Crear tabs para organizar las visualizaciones
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "üè∑Ô∏è MeSH Terms",
            "üìà Impacto",
            "üî¨ Evidencia",
            "üí∞ Financiamiento",
            "ü§ù Colaboraci√≥n",
            "üåç Mapa Mundial"
        ])

        # TAB 1: T√©rminos MeSH
        with tab1:
            st.markdown("### Vocabulario Biom√©dico Internacional")
            st.markdown("""
            Los **t√©rminos MeSH** (Medical Subject Headings) son el vocabulario controlado de la
            **Biblioteca Nacional de Medicina de EE.UU.** (NLM/NIH), permitiendo comparabilidad internacional.
            """)

            col1, col2 = st.columns([2, 1])

            with col1:
                fig_mesh = create_mesh_terms_chart(pubmed_data)
                if fig_mesh:
                    st.plotly_chart(fig_mesh, use_container_width=True)

            with col2:
                st.markdown("#### üîç T√©rminos Destacados")
                st.info("""
                **Top √°reas:**
                - **Mexico** (51): Contexto regional
                - **Obesity** (24): √Årea central
                - **Lupus/Arthritis** (31): Autoinmunes
                - **COVID-19** (13): Respuesta a crisis
                - **Biomarkers** (13): Medicina personalizada
                """)

                st.success("""
                ‚úÖ **Ventaja**: Indexaci√≥n internacional en PubMed aumenta visibilidad global.
                """)

        # TAB 2: Impacto Cient√≠fico
        with tab2:
            st.markdown("### Impacto Cient√≠fico y Citaciones")
            st.markdown("""
            Las **citaciones** reflejan cu√°ntas veces otros investigadores han referenciado el trabajo del programa.
            """)

            # M√©tricas de impacto
            metrics, fig_citations = create_citations_metrics_and_chart(pubmed_data)

            if metrics:
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric(
                        label="Total de Citaciones",
                        value=f"{metrics['total']:,}",
                        delta="Impacto Acumulado"
                    )

                with col2:
                    st.metric(
                        label="Promedio por Art√≠culo",
                        value=f"{metrics['average']:.1f}",
                        delta=f"{metrics['count']} art√≠culos citados"
                    )

                with col3:
                    st.metric(
                        label="Art√≠culo M√°s Citado",
                        value=f"{metrics['max']} citas"
                    )

                with col4:
                    st.metric(
                        label="h-index del Programa",
                        value=metrics['h_index'],
                        delta="Indicador de productividad"
                    )

                st.markdown("")

                # Gr√°fica de distribuci√≥n
                if fig_citations:
                    col1, col2 = st.columns([2, 1])

                    with col1:
                        st.plotly_chart(fig_citations, use_container_width=True)

                    with col2:
                        st.markdown("#### üìä Interpretaci√≥n")
                        st.info(f"""
                        **h-index {metrics['h_index']}**: {metrics['h_index']} art√≠culos con ‚â•{metrics['h_index']} citas.

                        **Contexto:**
                        - Programa joven (2019-2025)
                        - {metrics['average']:.1f} citas/art√≠culo **competitivo**
                        - {metrics['total']:,} citas = reconocimiento internacional
                        """)

                # Top art√≠culos citados
                st.markdown("#### üèÜ Top 10 Art√≠culos M√°s Citados")

                top_cited = create_top_cited_articles(pubmed_data, top_n=10)

                if top_cited:
                    for i, article in enumerate(top_cited, 1):
                        with st.expander(f"#{i} - {article['citations']} citas - {article['title'][:80]}..."):
                            st.markdown(f"""
                            **PMID:** [{article['pmid']}](https://pubmed.ncbi.nlm.nih.gov/{article['pmid']}/)
                            **A√±o:** {article['year']} | **Revista:** {article['journal']}
                            **Citaciones:** {article['citations']}

                            **T√≠tulo:** {article['title']}
                            """)

        # TAB 3: Pir√°mide de Evidencia
        with tab3:
            st.markdown("### Pir√°mide de Evidencia Cient√≠fica")
            st.markdown("""
            Clasificaci√≥n por **rigor metodol√≥gico**. La capacidad de producir diferentes tipos
            de evidencia demuestra **versatilidad cient√≠fica**.
            """)

            fig_pyramid = create_evidence_pyramid_chart(pubmed_data)

            if fig_pyramid:
                col1, col2 = st.columns([2, 1])

                with col1:
                    st.plotly_chart(fig_pyramid, use_container_width=True)

                with col2:
                    st.markdown("#### üéØ Calidad Metodol√≥gica")
                    st.success("""
                    **Alto Nivel:**
                    - 2 Meta-An√°lisis
                    - 7 Rev. Sistem√°ticas
                    - 3 RCTs

                    **12 estudios** de m√°xima calidad.
                    """)

                    st.info("""
                    **36 Revisiones** = liderazgo en s√≠ntesis de conocimiento.
                    """)

        # TAB 4: Financiamiento
        with tab4:
            st.markdown("### Financiamiento Competitivo")
            st.markdown("""
            Indicador de **calidad cient√≠fica**: requiere evaluaci√≥n por pares y demostrar pertinencia.
            """)

            funding_metrics, fig_funding = create_funding_analysis(pubmed_data)

            if funding_metrics:
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric(
                        label="Art√≠culos Financiados",
                        value=funding_metrics['funded'],
                        delta=f"{funding_metrics['percentage']:.1f}%"
                    )

                with col2:
                    st.metric(
                        label="Total Art√≠culos",
                        value=funding_metrics['total']
                    )

                with col3:
                    if funding_metrics['percentage'] >= 25:
                        st.success("‚úÖ **Excelente**")
                    else:
                        st.info("üìä **Bueno**")

                if fig_funding:
                    st.plotly_chart(fig_funding, use_container_width=True)

                    st.info("""
                    **CONACYT/SEP** lideran el financiamiento:
                    - Alineaci√≥n con prioridades nacionales
                    - Competitividad en convocatorias federales
                    - Reconocimiento de calidad cient√≠fica
                    """)

        # TAB 5: Red de Colaboraci√≥n Nacional
        with tab5:
            st.markdown("### Red de Colaboraci√≥n Institucional")
            st.markdown("""
            **Inserci√≥n** en ecosistema cient√≠fico nacional. Colaboraciones multi-institucionales
            generan sinergias.
            """)

            top_collab = create_collaboration_network_data(pubmed_data)

            if top_collab:
                st.markdown("#### üåê Top 10 Instituciones")

                col1, col2 = st.columns(2)

                for i, (institution, count) in enumerate(top_collab):
                    if i < 5:
                        with col1:
                            st.metric(
                                label=institution,
                                value=f"{count} art√≠culos",
                                delta="Co-autor√≠a"
                            )
                    else:
                        with col2:
                            st.metric(
                                label=institution,
                                value=f"{count} art√≠culos",
                                delta="Co-autor√≠a"
                            )

                st.success("""
                ‚úÖ **Red Consolidada**: Colaboraciones con IMSS, hospitales y universidades:
                - Trabajo multi-institucional
                - Acceso a infraestructura diversa
                - Transferencia al sector salud
                - Modelo academia-servicios
                """)

        # TAB 6: Mapa Mundial
        with tab6:
            st.markdown("### Mapa de Colaboraci√≥n Internacional")
            st.markdown("""
            Visualizaci√≥n geogr√°fica de colaboraciones cient√≠ficas del DCNT-UdeG con instituciones
            de otros pa√≠ses, demostrando alcance global.
            """)

            map_result = create_collaboration_map(pubmed_data)

            if map_result:
                fig_map, df_map = map_result
                st.plotly_chart(fig_map, use_container_width=True)

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("#### üåé Pa√≠ses Colaboradores")
                    df_map_sorted = df_map.sort_values('Articles', ascending=False)
                    st.dataframe(df_map_sorted, use_container_width=True, hide_index=True)

                with col2:
                    st.markdown("#### üåê Alcance Global")
                    st.metric("Total de Pa√≠ses", len(df_map))
                    st.metric("Pa√≠s Principal", df_map_sorted.iloc[0]['Country'])
                    st.metric("Art√≠culos m√°s citados", df_map_sorted.iloc[0]['Articles'])

                st.info("""
                **Colaboraci√≥n Internacional**:
                - Mayor concentraci√≥n en M√©xico (sede del programa)
                - Colaboraciones con USA, Espa√±a y Latinoam√©rica
                - Presencia en Europa y Asia
                - Red global demuestra competitividad internacional
                """)

    else:
        st.warning("‚ö†Ô∏è No se encontraron datos de PubMed. Verifica que exista el archivo metadata_updated_20251024_043156.json")

    st.markdown("---")

    # SECCI√ìN 4.5: L√≠neas de Investigaci√≥n del Doctorado
    st.markdown('<div class="section-header">üéì L√≠neas de Investigaci√≥n del DCNT-UdeG</div>', unsafe_allow_html=True)

    st.markdown("""
    El DCNT-UdeG opera con **tres l√≠neas de investigaci√≥n complementarias** que cubren todo el espectro
    de la investigaci√≥n traslacional en nutrici√≥n: desde mecanismos moleculares hasta intervenciones poblacionales.
    """)

    # Verificar si hay datos de clasificaci√≥n
    if lineas_data and 'estadisticas' in lineas_data:
        stats = lineas_data['estadisticas']

        # M√©tricas principales
        st.markdown("### üìä Clasificaci√≥n de Art√≠culos por L√≠nea de Investigaci√≥n")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "Total Clasificados",
                stats['total_articulos'],
                delta="100% Cobertura"
            )

        with col2:
            st.metric(
                "Multi-L√≠nea",
                stats['multi_linea'],
                delta=f"{stats['multi_linea']/stats['total_articulos']*100:.1f}%"
            )

        with col3:
            alta_confianza = stats['por_confianza']['alta']
            st.metric(
                "Alta Confianza",
                alta_confianza,
                delta=f"{alta_confianza/stats['total_articulos']*100:.1f}%"
            )

        with col4:
            st.metric(
                "M√©todo",
                "Embeddings ML",
                delta="Similitud Coseno"
            )

        st.markdown("")

        # Gr√°fica de distribuci√≥n
        fig_dist = create_lineas_distribution_chart(lineas_data)
        if fig_dist:
            st.plotly_chart(fig_dist, use_container_width=True)

        # Informaci√≥n sobre la metodolog√≠a
        with st.expander("‚ÑπÔ∏è Metodolog√≠a de Clasificaci√≥n (Detalles T√©cnicos)"):
            metadata = lineas_data.get('metadata', {})
            umbrales = metadata.get('umbrales', {})

            col1, col2 = st.columns(2)

            with col1:
                st.markdown(f"""
                **M√©todo de Clasificaci√≥n:**
                - **Embeddings + Similitud Coseno**
                - Modelo: `paraphrase-multilingual-MiniLM-L12-v2`
                - Clasificaci√≥n basada en similitud sem√°ntica real
                - Multiling√ºe (espa√±ol + ingl√©s)

                **Umbrales de Similitud:**
                - L√≠nea Principal: Similitud ‚â• 0.35 (35%)
                - L√≠nea Secundaria: Similitud ‚â• 0.30 (30%)
                - Multi-l√≠nea: Art√≠culos con m√∫ltiples l√≠neas ‚â• umbral secundario

                **Datos Utilizados:**
                - T√≠tulo completo del art√≠culo
                - Abstract (92.5% disponibles)
                - MeSH terms (vocabulario controlado)
                - Keywords del autor
                """)

            with col2:
                st.markdown(f"""
                **Niveles de Confianza:**
                - üü¢ **Alta** (‚â•50%): {stats['por_confianza'].get('alta', 0)} art√≠culos
                - üü° **Media** (40-50%): {stats['por_confianza'].get('media', 0)} art√≠culos
                - üü† **Baja** (35-40%): {stats['por_confianza'].get('baja', 0)} art√≠culos
                - üî¥ **Tentativa** (<35%): {stats['por_confianza'].get('tentativa', 0)} art√≠culos

                **Caracter√≠sticas del Modelo:**
                - Tama√±o: ~420 MB
                - Arquitectura: Sentence Transformers
                - Embeddings: 384 dimensiones
                - Velocidad: ~30 segundos (226 art√≠culos)
                - Distribuci√≥n equilibrada sin sesgos
                """)

        # An√°lisis de art√≠culos multi-l√≠nea
        if stats['multi_linea'] > 0:
            st.markdown("### üîó An√°lisis de Art√≠culos Multi-L√≠nea")

            st.info(f"""
            **{stats['multi_linea']} art√≠culos ({stats['multi_linea']/stats['total_articulos']*100:.1f}%)**
            pertenecen a m√∫ltiples l√≠neas de investigaci√≥n, demostrando el car√°cter **interdisciplinario**
            de la investigaci√≥n del DCNT-UdeG.
            """)

            col1, col2 = st.columns(2)

            with col1:
                fig_upset = create_upset_plot(lineas_data)
                if fig_upset:
                    st.plotly_chart(fig_upset, use_container_width=True)

            with col2:
                fig_matrix = create_lineas_cooccurrence_matrix(lineas_data)
                if fig_matrix:
                    st.plotly_chart(fig_matrix, use_container_width=True)

        st.markdown("---")

    else:
        st.warning("""
        ‚ö†Ô∏è **Datos de clasificaci√≥n de l√≠neas no disponibles**

        Los datos de clasificaci√≥n por l√≠neas de investigaci√≥n no est√°n disponibles.
        Para regenerar estos datos, ejecuta:
        1. `python src/embeddings_classifier.py` - Clasificaci√≥n con Embeddings
        2. `python src/convert_embeddings_to_dashboard.py` - Conversi√≥n a formato dashboard
        """)

    # Tabs por l√≠nea
    st.markdown("### üìö Descripci√≥n y Art√≠culos por L√≠nea")

    tab1, tab2, tab3 = st.tabs([
        "üß¨ L√≠nea 1: Bases Moleculares y Gen√≥mica Nutricional",
        "üè• L√≠nea 2: Epidemiolog√≠a Cl√≠nica y Factores de Riesgo",
        "üë• L√≠nea 3: Salud Poblacional y Pol√≠ticas P√∫blicas"
    ])

    with tab1:
        linea1 = LINEAS_INVESTIGACION['linea_1']
        col1, col2 = st.columns([3, 2])

        with col1:
            st.markdown(f"### {linea1['nombre']}")
            st.markdown(f"**{linea1['descripcion']}**")

            st.markdown("**√Åreas de Investigaci√≥n:**")
            for area in linea1['areas_investigacion']:
                st.markdown(f"- {area}")

        with col2:
            st.info(f"""
            **Fase Traslacional:** T0-T1 (B√°sica a Cl√≠nica)

            **Aplicaciones:**
            - {linea1['aplicaciones'][0]}
            - {linea1['aplicaciones'][1]}
            - {linea1['aplicaciones'][2]}

            **Campo Laboral:**
            - {linea1['campo_laboral'][0]}
            - {linea1['campo_laboral'][1]}
            - {linea1['campo_laboral'][2]}
            """)

        st.success("""
        **Relevancia √önica para M√©xico:** La poblaci√≥n mexicana tiene alta diversidad gen√©tica por su composici√≥n
        mestiza e ind√≠gena √∫nica. La investigaci√≥n nutrigen√≥mica espec√≠fica en poblaci√≥n local NO es extrapolable
        de estudios europeos o asi√°ticos.
        """)

        # Tabla de art√≠culos clasificados en L√≠nea 1
        if lineas_data:
            st.markdown("---")
            st.markdown("#### üìÑ Art√≠culos Clasificados en esta L√≠nea")

            df_linea1 = filter_articulos_by_linea(lineas_data, 1)

            if not df_linea1.empty:
                # M√©tricas de la l√≠nea
                col_m1, col_m2, col_m3 = st.columns(3)
                with col_m1:
                    st.metric("Total Art√≠culos", len(df_linea1))
                with col_m2:
                    principales = len(df_linea1[df_linea1['Tipo'] == 'Principal'])
                    st.metric("L√≠nea Principal", principales)
                with col_m3:
                    alta_conf = len(df_linea1[df_linea1['Confianza'] == 'Alta'])
                    st.metric("Alta Confianza", alta_conf)

                # Filtros
                col_f1, col_f2 = st.columns(2)
                with col_f1:
                    a√±os_disponibles = sorted(df_linea1['A√±o'].unique())
                    a√±o_filtro = st.multiselect(
                        "Filtrar por A√±o",
                        options=a√±os_disponibles,
                        default=a√±os_disponibles,
                        key="a√±o_l1"
                    )
                with col_f2:
                    confianza_filtro = st.multiselect(
                        "Filtrar por Confianza",
                        options=['Alta', 'Media', 'Baja', 'Tentativa'],
                        default=['Alta', 'Media', 'Baja', 'Tentativa'],
                        key="conf_l1"
                    )

                # Aplicar filtros
                df_filtrado = df_linea1[
                    (df_linea1['A√±o'].isin(a√±o_filtro)) &
                    (df_linea1['Confianza'].isin(confianza_filtro))
                ]

                st.dataframe(
                    df_filtrado,
                    use_container_width=True,
                    height=400,
                    hide_index=True
                )

                # Bot√≥n de descarga
                csv = df_filtrado.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• Descargar tabla como CSV",
                    data=csv,
                    file_name='linea1_genomica_nutricional.csv',
                    mime='text/csv',
                    key="download_l1"
                )
            else:
                st.info("No hay art√≠culos clasificados en esta l√≠nea.")

    with tab2:
        linea2 = LINEAS_INVESTIGACION['linea_2']
        col1, col2 = st.columns([3, 2])

        with col1:
            st.markdown(f"### {linea2['nombre']}")
            st.markdown(f"**{linea2['descripcion']}**")

            st.markdown("**√Åreas de Investigaci√≥n:**")
            for area in linea2['areas_investigacion']:
                st.markdown(f"- {area}")

        with col2:
            st.info(f"""
            **Fase Traslacional:** T3-T4 (Pr√°ctica a Poblaci√≥n)

            **Aplicaciones:**
            - {linea2['aplicaciones'][0]}
            - {linea2['aplicaciones'][1]}
            - {linea2['aplicaciones'][3]}

            **Campo Laboral:**
            - {linea2['campo_laboral'][0]}
            - {linea2['campo_laboral'][1]}
            - {linea2['campo_laboral'][2]}
            """)

        st.success("""
        **Impacto en Salud P√∫blica:** Forma investigadores con competencias para dise√±ar, implementar y
        evaluar intervenciones nutricionales poblacionales, contribuyendo a la generaci√≥n de evidencia
        cient√≠fica que pueda informar pol√≠ticas p√∫blicas basadas en el contexto mexicano.
        """)

        # Tabla de art√≠culos clasificados en L√≠nea 2
        if lineas_data:
            st.markdown("---")
            st.markdown("#### üìÑ Art√≠culos Clasificados en esta L√≠nea")

            df_linea2 = filter_articulos_by_linea(lineas_data, 2)

            if not df_linea2.empty:
                # M√©tricas de la l√≠nea
                col_m1, col_m2, col_m3 = st.columns(3)
                with col_m1:
                    st.metric("Total Art√≠culos", len(df_linea2))
                with col_m2:
                    principales = len(df_linea2[df_linea2['Tipo'] == 'Principal'])
                    st.metric("L√≠nea Principal", principales)
                with col_m3:
                    alta_conf = len(df_linea2[df_linea2['Confianza'] == 'Alta'])
                    st.metric("Alta Confianza", alta_conf)

                # Filtros
                col_f1, col_f2 = st.columns(2)
                with col_f1:
                    a√±os_disponibles = sorted(df_linea2['A√±o'].unique())
                    a√±o_filtro = st.multiselect(
                        "Filtrar por A√±o",
                        options=a√±os_disponibles,
                        default=a√±os_disponibles,
                        key="a√±o_l2"
                    )
                with col_f2:
                    confianza_filtro = st.multiselect(
                        "Filtrar por Confianza",
                        options=['Alta', 'Media', 'Baja', 'Tentativa'],
                        default=['Alta', 'Media', 'Baja', 'Tentativa'],
                        key="conf_l2"
                    )

                # Aplicar filtros
                df_filtrado = df_linea2[
                    (df_linea2['A√±o'].isin(a√±o_filtro)) &
                    (df_linea2['Confianza'].isin(confianza_filtro))
                ]

                st.dataframe(
                    df_filtrado,
                    use_container_width=True,
                    height=400,
                    hide_index=True
                )

                # Bot√≥n de descarga
                csv = df_filtrado.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• Descargar tabla como CSV",
                    data=csv,
                    file_name='linea2_salud_publica.csv',
                    mime='text/csv',
                    key="download_l2"
                )
            else:
                st.info("No hay art√≠culos clasificados en esta l√≠nea.")

    with tab3:
        linea3 = LINEAS_INVESTIGACION['linea_3']
        col1, col2 = st.columns([3, 2])

        with col1:
            st.markdown(f"### {linea3['nombre']}")
            st.markdown(f"**{linea3['descripcion']}**")

            st.markdown("**√Åreas de Investigaci√≥n:**")
            for area in linea3['areas_investigacion']:
                st.markdown(f"- {area}")

        with col2:
            st.info(f"""
            **Fase Traslacional:** T1-T2 (Cl√≠nica a Pacientes)

            **Aplicaciones:**
            - {linea3['aplicaciones'][0]}
            - {linea3['aplicaciones'][1]}
            - {linea3['aplicaciones'][2]}

            **Campo Laboral:**
            - {linea3['campo_laboral'][0]}
            - {linea3['campo_laboral'][1]}
            - {linea3['campo_laboral'][3]}
            """)

        st.success("""
        **Biodiversidad Mexicana:** Investigaci√≥n puede desarrollar alimentos funcionales aprovechando
        biodiversidad √∫nica (nopal, amaranto, ch√≠a, quelites, aguamiel) reduciendo dependencia de importaciones
        y promoviendo sistemas alimentarios sostenibles.
        """)

        # Tabla de art√≠culos clasificados en L√≠nea 3
        if lineas_data:
            st.markdown("---")
            st.markdown("#### üìÑ Art√≠culos Clasificados en esta L√≠nea")

            df_linea3 = filter_articulos_by_linea(lineas_data, 3)

            if not df_linea3.empty:
                # M√©tricas de la l√≠nea
                col_m1, col_m2, col_m3 = st.columns(3)
                with col_m1:
                    st.metric("Total Art√≠culos", len(df_linea3))
                with col_m2:
                    principales = len(df_linea3[df_linea3['Tipo'] == 'Principal'])
                    st.metric("L√≠nea Principal", principales)
                with col_m3:
                    alta_conf = len(df_linea3[df_linea3['Confianza'] == 'Alta'])
                    st.metric("Alta Confianza", alta_conf)

                # Filtros
                col_f1, col_f2 = st.columns(2)
                with col_f1:
                    a√±os_disponibles = sorted(df_linea3['A√±o'].unique())
                    a√±o_filtro = st.multiselect(
                        "Filtrar por A√±o",
                        options=a√±os_disponibles,
                        default=a√±os_disponibles,
                        key="a√±o_l3"
                    )
                with col_f2:
                    confianza_filtro = st.multiselect(
                        "Filtrar por Confianza",
                        options=['Alta', 'Media', 'Baja', 'Tentativa'],
                        default=['Alta', 'Media', 'Baja', 'Tentativa'],
                        key="conf_l3"
                    )

                # Aplicar filtros
                df_filtrado = df_linea3[
                    (df_linea3['A√±o'].isin(a√±o_filtro)) &
                    (df_linea3['Confianza'].isin(confianza_filtro))
                ]

                st.dataframe(
                    df_filtrado,
                    use_container_width=True,
                    height=400,
                    hide_index=True
                )

                # Bot√≥n de descarga
                csv = df_filtrado.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• Descargar tabla como CSV",
                    data=csv,
                    file_name='linea3_alimentacion_nutricion.csv',
                    mime='text/csv',
                    key="download_l3"
                )
            else:
                st.info("No hay art√≠culos clasificados en esta l√≠nea.")

    st.markdown("---")

    # # SECCI√ìN 5: Impacto en Problemas Alimentario-Nutricios (DESACTIVADA)
    # st.markdown('<div class="section-header">üçé Impacto en Problem√°ticas Alimentario-Nutricias de M√©xico</div>', unsafe_allow_html=True)

    # st.markdown("""
    # La investigaci√≥n del DCNT-UdeG aborda las **4 problem√°ticas alimentario-nutricias cr√≠ticas** identificadas
    # en el an√°lisis epidemiol√≥gico nacional actualizado (ENSANUT 2022-2023, Sistema de Vigilancia 2024).
    # """)

    #     # # Problema 1: Epidemia de obesidad
    #     # with st.expander("üö® 1. EPIDEMIA DE OBESIDAD Y ENFERMEDADES METAB√ìLICAS SIN CONTROL", expanded=True):
    #         col1, col2, col3 = st.columns(3)
    # 
    #         with col1:
    #             st.metric("Sobrepeso/Obesidad Adultos", "75.2%", "38.3% sobrepeso + 36.9% obesidad")
    #             st.caption("ENSANUT 2022")
    # 
    #         with col2:
    #             st.metric("Diabetes Adultos", "18.3%", "14.6 millones de personas")
    #             st.caption("ENSANUT 2022")
    # 
    #         with col3:
    #             st.metric("Sin Atenci√≥n Nutricional", "56.5%", "Diab√©ticos hospitalizados")
    #             st.caption("Vigilancia Hospitalaria 2023")
    # 
    #         st.markdown(f"""
    #         **Situaci√≥n:**
    #         - **Obesidad abdominal:** {EPIDEMIOLOGIA_MEXICO['obesidad_abdominal']['valor']}% de adultos
    #         - **Mortalidad:** {EPIDEMIOLOGIA_MEXICO['mortalidad_diabetes']['valor']:,} muertes por diabetes en 2023
    #         - **Actividad f√≠sica inadecuada:** Solo 15.7% de diab√©ticos hace actividad f√≠sica diaria adecuada
    #         - **Proyecci√≥n:** 88% con sobrepeso/obesidad para 2050 sin intervenciones efectivas
    # 
    #         **Contribuci√≥n del DCNT-UdeG:**
    #         - **L√≠nea 1 (Gen√≥mica):** Identificar variantes gen√©ticas que predisponen a diabetes/obesidad en poblaci√≥n mexicana
    #         - **L√≠nea 2 (Salud P√∫blica):** Dise√±ar intervenciones escalables para prevenci√≥n primaria
    #         - **L√≠nea 3 (Alimentaci√≥n):** Desarrollar protocolos efectivos de atenci√≥n nutricional para los 580 centros de salud de Jalisco
    #         """)
    # 
    #     # Problema 2: Desnutrici√≥n infantil
    #     with st.expander("üìâ 2. DESNUTRICI√ìN INFANTIL ESTANCADA CON INCREMENTOS ALARMANTES"):
    #         col1, col2, col3 = st.columns(3)
    # 
    #         with col1:
    #             st.metric("Baja Talla Infantil", "12.8%", "Estancado desde 2012", delta_color="inverse")
    # 
    #         with col2:
    #             st.metric("Anemia Mujeres", "15.8%", "‚Üë de 11.6% en 2012", delta_color="inverse")
    # 
    #         with col3:
    #             st.metric("Jalisco Desnutrici√≥n", "+88%", "Incremento 2021-2023", delta_color="inverse")
    # 
    #         st.markdown(f"""
    #         **Situaci√≥n:**
    #         - **Nacional:** {EPIDEMIOLOGIA_MEXICO['desnutricion_infantil']['valor']}% ni√±os menores de 5 a√±os con baja talla (sin avances desde 2012)
    #         - **Poblaci√≥n ind√≠gena:** 27.4% baja talla vs 13.9% promedio nacional
    #         - **Jalisco:** {EPIDEMIOLOGIA_JALISCO['desnutricion_casos']['2023']:,} casos en 2023 (vs {EPIDEMIOLOGIA_JALISCO['desnutricion_casos']['2021']:,} en 2021) = **{EPIDEMIOLOGIA_JALISCO['desnutricion_casos']['incremento_porcentual']}% incremento**
    #         - **Meta global:** M√©xico proyectado a cumplir solo 1 de 6 metas nutricionales para 2025/2030
    # 
    #         **Contribuci√≥n del DCNT-UdeG:**
    #         - **Investigaci√≥n primeros 1000 d√≠as:** Gen√≥mica nutricional y epigen√©tica para identificar ventanas cr√≠ticas de intervenci√≥n
    #         - **Suplementaci√≥n guiada por biomarcadores:** M√°s efectiva que suplementaci√≥n universal
    #         - **Evaluaci√≥n rigurosa:** Programas DIF Jalisco "Primeros 1000 D√≠as" para mejorarlos y escalarlos
    #         """)
    # 
    #     # Problema 3: Transici√≥n nutricional
    #     with st.expander("üçî 3. TRANSICI√ìN NUTRICIONAL CON CAMBIOS DIET√âTICOS PERJUDICIALES"):
    #         col1, col2 = st.columns(2)
    # 
    #         with col1:
    #             st.metric("Consumo Ultraprocesados", "46.6%", "+7.1 puntos en 20 a√±os", delta_color="inverse")
    # 
    #         with col2:
    #             st.metric("Muertes Diabetes por Bebidas", "27%", "Relacionadas con bebidas azucaradas", delta_color="inverse")
    # 
    #         st.markdown(f"""
    #         **Situaci√≥n:**
    #         - **Ultraprocesados:** {EPIDEMIOLOGIA_MEXICO['ultraprocesados']['valor']}% del consumo total (incremento de 7.1 puntos 2000-2020)
    #         - **Bebidas azucaradas:** 163 litros per c√°pita/a√±o, 27% de muertes por diabetes relacionadas
    #         - **Frutas y verduras:** Menos del 50% consume regularmente
    #         - **Ni√±os peque√±os:** 42% consume alimentos no saludables (6-23 meses), 87% preescolares consume bebidas endulzadas
    # 
    #         **Contribuci√≥n del DCNT-UdeG:**
    #         - **Estudios de aceptabilidad:** Alimentos tradicionales saludables vs ultraprocesados
    #         - **Evaluaci√≥n etiquetado frontal:** Implementado en M√©xico desde 2020
    #         - **Alimentos funcionales:** Basados en biodiversidad mexicana (nopal, amaranto, ch√≠a, aguamiel)
    #         - **Educaci√≥n nutricional:** Estrategias culturalmente apropiadas
    #         """)
    # 
    #     # Problema 4: Inseguridad alimentaria
    #     with st.expander("üçû 4. INSEGURIDAD ALIMENTARIA PERSISTENTE CON BRECHAS SOCIOECON√ìMICAS"):
    #         col1, col2 = st.columns(2)
    # 
    #         with col1:
    #             st.metric("Carencia Alimentaria Nacional", "18.2%", "23.4 millones mexicanos", delta_color="inverse")
    # 
    #         with col2:
    #             st.metric("Carencia Jalisco", "1,176,459", "Personas sin acceso", delta_color="inverse")
    # 
    #         st.markdown(f"""
    #         **Situaci√≥n:**
    #         - **Nacional:** {EPIDEMIOLOGIA_MEXICO['inseguridad_alimentaria']['valor']}% poblaci√≥n ({EPIDEMIOLOGIA_MEXICO['inseguridad_alimentaria']['personas']})
    #         - **Inseguridad severa:** 8.2 millones de mexicanos
    #         - **Desperdicio alimentario:** 20.4 millones ton/a√±o (34% producci√≥n) mientras hay inseguridad alimentaria
    #         - **Anemia en vulnerables:** 34.3% en mujeres con menores capacidades econ√≥micas
    # 
    #         **Contribuci√≥n del DCNT-UdeG:**
    #         - **Fuentes bajo costo:** Identificar alimentos de bajo costo y alto valor nutricional (biodiversidad local)
    #         - **Evaluaci√≥n programas sociales:** Sembrando Vida (441,466 beneficiarios), J√≥venes Construyendo el Futuro
    #         - **Intervenciones costo-efectivas:** Viables en contextos de pobreza
    #         - **Reducci√≥n inequidades:** Investigaci√≥n culturalmente pertinente (25+ a√±os con Wix√°rikas)
    #         """)
    # 
    st.markdown("---")

    # SECCI√ìN 6: Pertinencia Regional
    st.markdown('<div class="section-header">üó∫Ô∏è Pertinencia Regional: Jalisco como Epicentro de Crisis Nutricional</div>', unsafe_allow_html=True)

    st.markdown("""
    El DCNT-UdeG no es un programa acad√©mico abstracto sino una **respuesta institucional urgente a crisis
    de salud p√∫blica regional**. Jalisco y la regi√≥n Occidente presentan problem√°ticas espec√≠ficas que justifican
    este programa doctoral √∫nico en la regi√≥n.
    """)

    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown("### üö® Crisis en Jalisco")

        st.error(f"""
        **Jalisco: {EPIDEMIOLOGIA_JALISCO['desnutricion_casos']['ranking']} en desnutrici√≥n infantil**

        - **{EPIDEMIOLOGIA_JALISCO['desnutricion_casos']['2023']:,} casos** en 2023
        - **+{EPIDEMIOLOGIA_JALISCO['desnutricion_casos']['incremento_porcentual']}%** incremento desde 2021
        - **{EPIDEMIOLOGIA_JALISCO['muertes_obesidad']['asociadas_obesidad']:,} muertes anuales** asociadas a obesidad ({EPIDEMIOLOGIA_JALISCO['muertes_obesidad']['porcentaje']}% del total)
        """)

        st.warning(f"""
        **Brechas Cr√≠ticas en Atenci√≥n:**

        - **{EPIDEMIOLOGIA_JALISCO['sin_atencion_nutricional']['valor']}%** de diab√©ticos hospitalizados **NO reciben atenci√≥n nutricional**
        - **{EPIDEMIOLOGIA_JALISCO['carencia_alimentaria']['personas']:,} personas** con carencia de acceso a alimentaci√≥n
        - **{EPIDEMIOLOGIA_JALISCO['diabetes_casos']['ranking']}** junto con CDMX
        """)

    with col2:
        st.markdown("### üåé Alcance Regional")

        st.info(f"""
        **Regi√≥n Occidente:**

        - **Poblaci√≥n:** {REGION_OCCIDENTE['poblacion']}
        - **PIB Nacional:** {REGION_OCCIDENTE['pib_nacional']}
        - **Estados:** {', '.join(REGION_OCCIDENTE['estados'])}

        **Jalisco como L√≠der:**
        - {REGION_OCCIDENTE['lider_regional']['economia']}
        - {REGION_OCCIDENTE['lider_regional']['pib_regional']} del PIB regional
        - IPS: {REGION_OCCIDENTE['lider_regional']['ips']} (mejor de la regi√≥n)
        """)

        st.success(f"""
        **Vac√≠o de Formaci√≥n Doctoral:**

        {REGION_OCCIDENTE['deficit_formacion']}
        """)

    #     # Infraestructura robusta
    #     st.markdown("### üèõÔ∏è Infraestructura Institucional Robusta Lista para Potenciar el Programa")
    # 
    #     col1, col2, col3 = st.columns(3)
    # 
    #     with col1:
    #         st.markdown("**CUCS - Universidad de Guadalajara**")
    #         st.metric("Investigadores SNI", INFRAESTRUCTURA_UDG['cucs']['investigadores_sni'])
    #         st.metric("Profesores Tiempo Completo", INFRAESTRUCTURA_UDG['cucs']['profesores_tiempo_completo'])
    #         st.metric("Art√≠culos Anuales", INFRAESTRUCTURA_UDG['cucs']['articulos_anuales'])
    # 
    #     with col2:
    #         st.markdown("**Hospital Civil de Guadalajara**")
    #         st.metric("Investigadores SNI", INFRAESTRUCTURA_UDG['hospital_civil']['investigadores_sni'])
    #         st.metric("Publicaciones Anuales", INFRAESTRUCTURA_UDG['hospital_civil']['publicaciones_anuales'])
    #         st.metric("Proyectos Activos", INFRAESTRUCTURA_UDG['hospital_civil']['proyectos_investigacion'])
    # 
    #     with col3:
    #         st.markdown("**Red Asistencial Jalisco**")
    #         st.metric("Centros de Salud", INFRAESTRUCTURA_UDG['ss_jalisco']['centros_salud'])
    #         st.metric("Hospitales", INFRAESTRUCTURA_UDG['ss_jalisco']['hospitales'])
    #         st.caption("Sistema urgencias mejor de Latinoam√©rica")
    # 
    #     st.success(f"""
    #     **INHU (Instituto de Nutrici√≥n Humana):**
    #     - **{INFRAESTRUCTURA_UDG['inhu']['a√±os_operacion']}** de experiencia en investigaci√≥n materno-infantil
    #     - Maestr√≠a en Nutrici√≥n Humana **{INFRAESTRUCTURA_UDG['inhu']['maestria_pnpc']}** en PNPC-CONAHCYT
    #     - **{INFRAESTRUCTURA_UDG['inhu']['generaciones_formadas']} generaciones** de egresados formados
    # 
    #     **CMNO-IMSS (Centro M√©dico Nacional de Occidente):**
    #     - **{INFRAESTRUCTURA_UDG['cmno_imss']['usuarios_potenciales']}** (30% de derechohabientes IMSS nacional)
    #     - {INFRAESTRUCTURA_UDG['cmno_imss']['infraestructura']}
    # 
    #     Esta infraestructura representa la base sobre la cual el DCNT-UdeG puede realizar **investigaci√≥n traslacional
    #     de impacto inmediato** escalable a nivel nacional.
    #     """)

    st.markdown("---")

    # SECCI√ìN 7: Tabla de Publicaciones
    st.markdown('<div class="section-header">üìö Publicaciones Detalladas</div>', unsafe_allow_html=True)

    # Selector de a√±o
    year_filter = st.selectbox("Filtrar por a√±o:", ["Todos"] + sorted(filtered_df['a√±o'].unique().tolist(), reverse=True))

    if year_filter != "Todos":
        display_df = filtered_df[filtered_df['a√±o'] == year_filter]
    else:
        display_df = filtered_df

    # Mostrar tabla
    st.dataframe(
        display_df[['a√±o', 'numero', 'titulo', 'revista', 'doi']].style.set_properties(**{
            'text-align': 'left'
        }),
        use_container_width=True,
        height=400
    )

    # Footer
    st.markdown("---")

    # Footer con logo al lado del texto
    footer_col1, footer_col_logo, footer_col_text, footer_col2 = st.columns([1, 1, 3, 1])

    with footer_col1:
        st.write("")  # Espacio

    with footer_col_logo:
        if logo_path.exists():
            st.image(str(logo_path), width=100)

    with footer_col_text:
        st.markdown("""
        <div style='color: #666; padding: 1rem 0;'>
            <p style='margin: 0.3rem 0;'><strong style='color: #1f77b4; font-size: 1.2rem;'>Doctorado en Ciencias de la Nutrici√≥n Traslacional</strong></p>
            <p style='margin: 0.2rem 0;'>Universidad de Guadalajara</p>
            <p style='margin: 0.2rem 0;'>Centro Universitario de Ciencias de la Salud (CUCS)</p>
            <p style='margin: 0.5rem 0 0 0; font-size: 0.75rem; color: #999;'>Desarrollado por: Jos√© Gerardo Mora Almanza - Alumno del DCNT</p>
        </div>
        """, unsafe_allow_html=True)

    with footer_col2:
        st.write("")  # Espacio


if __name__ == "__main__":
    main()
