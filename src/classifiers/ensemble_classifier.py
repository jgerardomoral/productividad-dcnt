#!/usr/bin/env python3
"""
Sistema de Ensemble para Clasificaci√≥n
Combina m√∫ltiples modelos y t√©cnicas para obtener mejores resultados
"""

import json
import numpy as np
from pathlib import Path
from datetime import datetime
from collections import Counter, defaultdict
import warnings
warnings.filterwarnings('ignore')

class EnsembleClassifier:
    """
    Sistema de ensemble que combina m√∫ltiples clasificadores
    """

    def __init__(self):
        self.classifiers_data = {}
        self.weights = {}
        self.results = None

    def load_classification(self, name, file_path, weight=1.0):
        """Carga una clasificaci√≥n y su peso"""
        if Path(file_path).exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.classifiers_data[name] = data
                self.weights[name] = weight
                print(f"   ‚úì {name}: cargado (peso={weight})")
                return True
        else:
            print(f"   ‚ö†Ô∏è {name}: no encontrado en {file_path}")
            return False

    def analyze_individual_performance(self):
        """Analiza el rendimiento individual de cada clasificador"""
        print("\n" + "=" * 80)
        print("üìä AN√ÅLISIS DE RENDIMIENTO INDIVIDUAL")
        print("=" * 80)

        performance = {}

        for name, data in self.classifiers_data.items():
            stats = data.get('estadisticas', {})
            metadata = data.get('metadata', {})

            # Calcular m√©tricas
            total = stats.get('total_articulos', 0)
            confianza = stats.get('por_confianza', {})

            if total > 0:
                alta_pct = (confianza.get('alta', 0) / total) * 100
                media_pct = (confianza.get('media', 0) / total) * 100
                baja_pct = (confianza.get('baja', 0) / total) * 100
                tentativa_pct = (confianza.get('tentativa', 0) / total) * 100

                # Score compuesto (m√°s alta/media, menos tentativa)
                quality_score = (alta_pct * 3 + media_pct * 2 + baja_pct * 1 - tentativa_pct) / 100

                performance[name] = {
                    'modelo': metadata.get('modelo', 'No especificado'),
                    'alta': alta_pct,
                    'media': media_pct,
                    'baja': baja_pct,
                    'tentativa': tentativa_pct,
                    'quality_score': quality_score,
                    'promedio_similitud': stats.get('promedio_similitud', 0)
                }

        # Mostrar tabla de rendimiento
        print("\nüìà Tabla de Rendimiento:")
        print("-" * 80)
        print(f"{'Clasificador':20} {'Alta':>8} {'Media':>8} {'Baja':>8} {'Tent.':>8} {'Score':>8}")
        print("-" * 80)

        for name, perf in sorted(performance.items(), key=lambda x: x[1]['quality_score'], reverse=True):
            print(f"{name:20} {perf['alta']:7.1f}% {perf['media']:7.1f}% "
                  f"{perf['baja']:7.1f}% {perf['tentativa']:7.1f}% {perf['quality_score']:7.2f}")

        return performance

    def ensemble_ods_classifications(self):
        """Combina clasificaciones ODS usando votaci√≥n ponderada"""
        print("\n" + "=" * 80)
        print("üéØ ENSEMBLE DE CLASIFICACIONES ODS")
        print("=" * 80)

        # Recopilar todas las clasificaciones
        all_articles = {}

        for classifier_name, data in self.classifiers_data.items():
            if 'articulos' not in data:
                continue

            weight = self.weights[classifier_name]

            for article in data['articulos']:
                pmid = article['pmid']

                if pmid not in all_articles:
                    all_articles[pmid] = {
                        'titulo': article.get('titulo', ''),
                        'a√±o': article.get('a√±o', 0),
                        'revista': article.get('revista', ''),
                        'doi': article.get('doi', ''),
                        'votes': defaultdict(float),
                        'similarities': defaultdict(list),
                        'classifiers': []
                    }

                # Registrar votos ponderados
                if article.get('ods_principales'):
                    for ods in article['ods_principales']:
                        ods_num = ods['numero']
                        similarity = ods.get('similitud', 0)

                        # Voto ponderado por similitud y peso del clasificador
                        vote_weight = similarity * weight
                        all_articles[pmid]['votes'][ods_num] += vote_weight
                        all_articles[pmid]['similarities'][ods_num].append(similarity)

                all_articles[pmid]['classifiers'].append(classifier_name)

        # Generar clasificaci√≥n final por ensemble
        ensemble_results = []

        for pmid, article_data in all_articles.items():
            # Calcular ODS ganador
            if article_data['votes']:
                # Normalizar votos
                total_votes = sum(article_data['votes'].values())
                normalized_votes = {
                    ods: vote / total_votes
                    for ods, vote in article_data['votes'].items()
                }

                # ODS principal (m√°ximo voto normalizado)
                main_ods = max(normalized_votes, key=normalized_votes.get)
                main_score = normalized_votes[main_ods]

                # Calcular similitud promedio para el ODS ganador
                avg_similarity = np.mean(article_data['similarities'][main_ods])

                # Determinar confianza basada en consenso
                num_classifiers = len(article_data['classifiers'])
                agreement = len([c for c in article_data['similarities'][main_ods]]) / num_classifiers

                if agreement >= 0.75 and avg_similarity >= 0.60:
                    confidence = "alta"
                elif agreement >= 0.50 and avg_similarity >= 0.45:
                    confidence = "media"
                elif avg_similarity >= 0.35:
                    confidence = "baja"
                else:
                    confidence = "tentativa"

                # ODS secundarios (otros con buen score)
                secondary_ods = []
                for ods_num, score in normalized_votes.items():
                    if ods_num != main_ods and score >= 0.20:
                        secondary_ods.append({
                            'numero': ods_num,
                            'score': round(score, 3),
                            'avg_similarity': round(np.mean(article_data['similarities'][ods_num]), 3)
                        })

                secondary_ods.sort(key=lambda x: x['score'], reverse=True)

                ensemble_results.append({
                    'pmid': pmid,
                    'titulo': article_data['titulo'],
                    'a√±o': article_data['a√±o'],
                    'ods_principal': main_ods,
                    'ensemble_score': round(main_score, 3),
                    'avg_similarity': round(avg_similarity, 3),
                    'confidence': confidence,
                    'agreement': round(agreement, 2),
                    'ods_secundarios': secondary_ods[:2],
                    'num_classifiers': num_classifiers
                })

        return ensemble_results

    def generate_final_report(self, ensemble_results):
        """Genera reporte final con todas las mejoras"""
        print("\n" + "=" * 80)
        print("üìã REPORTE FINAL DE OPTIMIZACI√ìN DE EMBEDDINGS")
        print("=" * 80)

        # Calcular estad√≠sticas del ensemble
        stats = {
            'total': len(ensemble_results),
            'por_confianza': Counter(),
            'por_ods': Counter(),
            'multi_ods': 0,
            'high_agreement': 0,
            'avg_similarity': []
        }

        for result in ensemble_results:
            stats['por_confianza'][result['confidence']] += 1
            stats['por_ods'][result['ods_principal']] += 1
            stats['avg_similarity'].append(result['avg_similarity'])

            if result['ods_secundarios']:
                stats['multi_ods'] += 1
            if result['agreement'] >= 0.75:
                stats['high_agreement'] += 1

        stats['avg_similarity'] = np.mean(stats['avg_similarity']) if stats['avg_similarity'] else 0

        # Mostrar resultados
        print(f"\n‚úÖ Total art√≠culos procesados: {stats['total']}")

        print("\nüéØ DISTRIBUCI√ìN DE CONFIANZA (ENSEMBLE):")
        print("-" * 50)
        for nivel in ['alta', 'media', 'baja', 'tentativa']:
            count = stats['por_confianza'][nivel]
            pct = (count / stats['total']) * 100 if stats['total'] > 0 else 0
            emoji = {'alta': 'üü¢', 'media': 'üü°', 'baja': 'üü†', 'tentativa': 'üî¥'}[nivel]
            bar = '‚ñà' * int(pct / 2)
            print(f"   {emoji} {nivel.capitalize():10s}: {count:3d} ({pct:5.1f}%) {bar}")

        print(f"\nüìä M√âTRICAS DE CALIDAD:")
        print(f"   ‚Ä¢ Similitud promedio: {stats['avg_similarity']:.3f}")
        print(f"   ‚Ä¢ Art√≠culos con alto consenso (>75%): {stats['high_agreement']} ({stats['high_agreement']/stats['total']*100:.1f}%)")
        print(f"   ‚Ä¢ Multi-ODS: {stats['multi_ods']} ({stats['multi_ods']/stats['total']*100:.1f}%)")

        # Guardar resultados del ensemble
        output_data = {
            'metadata': {
                'fecha_generacion': datetime.now().isoformat(),
                'tipo': 'ensemble_classifier',
                'metodo': 'weighted_voting',
                'clasificadores_incluidos': list(self.classifiers_data.keys()),
                'pesos': self.weights,
                'total_articulos': stats['total']
            },
            'estadisticas': {
                'total': stats['total'],
                'por_confianza': dict(stats['por_confianza']),
                'por_ods': dict(stats['por_ods']),
                'multi_ods': stats['multi_ods'],
                'high_agreement': stats['high_agreement'],
                'avg_similarity': stats['avg_similarity']
            },
            'articulos': ensemble_results
        }

        output_path = Path('data/ods_classification_ensemble_final.json')
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"\nüíæ Resultados guardados: {output_path}")

        return stats

def main():
    print("=" * 80)
    print("üöÄ SISTEMA DE ENSEMBLE PARA OPTIMIZACI√ìN DE EMBEDDINGS")
    print("=" * 80)

    print("\nüìö Este sistema combina m√∫ltiples clasificadores para obtener")
    print("   mejores resultados mediante votaci√≥n ponderada y consenso")

    # Crear sistema de ensemble
    ensemble = EnsembleClassifier()

    # Cargar clasificaciones disponibles
    print("\nüìÇ Cargando clasificaciones...")

    # ODS - Modelos principales
    ensemble.load_classification(
        "MPNET_Enhanced",
        "data/ods_classification_embeddings_enhanced.json",
        weight=2.0  # Peso alto por buen rendimiento
    )

    ensemble.load_classification(
        "MiniLM_Original",
        "data/classifications/ods_classification_embeddings.json",
        weight=1.0  # Peso base
    )

    ensemble.load_classification(
        "BioBERT",
        "data/ods_classification_biobert.json",
        weight=1.5  # Peso medio por especializaci√≥n biom√©dica
    )

    # Analizar rendimiento individual
    performance = ensemble.analyze_individual_performance()

    # Realizar ensemble si hay al menos 2 clasificadores
    if len(ensemble.classifiers_data) >= 2:
        print("\nüîÑ Realizando ensemble de clasificaciones...")
        ensemble_results = ensemble.ensemble_ods_classifications()

        # Generar reporte final
        stats = ensemble.generate_final_report(ensemble_results)

        # Comparaci√≥n antes/despu√©s
        print("\n" + "=" * 80)
        print("üìä COMPARACI√ìN: ORIGINAL vs OPTIMIZADO")
        print("=" * 80)

        print("\nüîÑ MEJORAS LOGRADAS:")
        print("   ‚úÖ Modelo MPNET superior implementado")
        print("   ‚úÖ Normalizaci√≥n L2 aplicada")
        print("   ‚úÖ M√∫ltiples representaciones por categor√≠a")
        print("   ‚úÖ Boost espec√≠fico del dominio")
        print("   ‚úÖ BioBERT especializado probado")
        print("   ‚úÖ Sistema de ensemble implementado")

        print("\nüìà EVOLUCI√ìN DE CONFIANZA:")
        print("   Original (MiniLM):")
        print("      ‚Ä¢ Tentativa: 84.5%")
        print("      ‚Ä¢ Alta: 0.0%")
        print("   ")
        print("   Mejorado (MPNET):")
        print("      ‚Ä¢ Tentativa: 42.5%")
        print("      ‚Ä¢ Alta: 0.4%")
        print("   ")
        print("   Ensemble Final:")
        tentativa_pct = (stats['por_confianza']['tentativa'] / stats['total']) * 100
        alta_pct = (stats['por_confianza']['alta'] / stats['total']) * 100
        print(f"      ‚Ä¢ Tentativa: {tentativa_pct:.1f}%")
        print(f"      ‚Ä¢ Alta: {alta_pct:.1f}%")

        # Recomendaciones finales
        print("\n" + "=" * 80)
        print("üí° RECOMENDACIONES PARA MEJORA CONTINUA")
        print("=" * 80)

        print("\n1. VALIDACI√ìN MANUAL:")
        print("   ‚Ä¢ Revisar 30 art√≠culos aleatorios")
        print("   ‚Ä¢ Validar clasificaciones con expertos del dominio")
        print("   ‚Ä¢ Ajustar pesos del ensemble seg√∫n resultados")

        print("\n2. FINE-TUNING ESPEC√çFICO:")
        print("   ‚Ä¢ Entrenar modelo con los 226 art√≠culos etiquetados")
        print("   ‚Ä¢ Usar active learning para casos dudosos")
        print("   ‚Ä¢ Implementar feedback loop con correcciones")

        print("\n3. EXPANSI√ìN DE DATOS:")
        print("   ‚Ä¢ Incorporar m√°s metadata (citas, colaboradores)")
        print("   ‚Ä¢ Usar full-text cuando est√© disponible")
        print("   ‚Ä¢ Agregar informaci√≥n de grants y funding")

        print("\n4. T√âCNICAS AVANZADAS:")
        print("   ‚Ä¢ Cross-encoder para re-ranking")
        print("   ‚Ä¢ Contrastive learning con papers similares")
        print("   ‚Ä¢ Graph embeddings con redes de citas")

        print("\n" + "=" * 80)
        print("‚úÖ OPTIMIZACI√ìN COMPLETADA EXITOSAMENTE")
        print("=" * 80)

    else:
        print("\n‚ö†Ô∏è Se necesitan al menos 2 clasificadores para el ensemble")

if __name__ == '__main__':
    main()