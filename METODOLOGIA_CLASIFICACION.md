# MetodologÃ­a de ClasificaciÃ³n - Sistema de Embeddings Avanzado

## ğŸ“‹ Resumen Ejecutivo

Este documento describe el sistema avanzado de clasificaciÃ³n automÃ¡tica implementado para categorizar las 226 publicaciones cientÃ­ficas del Doctorado en Ciencias de la NutriciÃ³n Traslacional (DCNT) segÃºn:
- **ODS** (Objetivos de Desarrollo Sostenible)
- **PRONACES** (Programas Nacionales EstratÃ©gicos)
- **LÃ­neas de InvestigaciÃ³n** del programa doctoral

## ğŸ¯ Problema Original

El sistema inicial presentaba limitaciones significativas:
- **84.5%** de clasificaciones con confianza "tentativa"
- **0%** de clasificaciones con alta confianza
- Similitud promedio de solo **0.35**
- Modelo bÃ¡sico (`all-MiniLM-L6-v2`) con 384 dimensiones

## ğŸš€ SoluciÃ³n Implementada: Sistema de Ensemble

### Arquitectura del Sistema

```mermaid
graph TD
    A[PublicaciÃ³n CientÃ­fica] --> B[ExtracciÃ³n de Metadata]
    B --> C[TÃ­tulo + Abstract + MeSH + Keywords]

    C --> D1[MPNET Embeddings]
    C --> D2[BioBERT Embeddings]
    C --> D3[MiniLM Embeddings]

    D1 --> E[VotaciÃ³n Ponderada]
    D2 --> E
    D3 --> E

    E --> F[ClasificaciÃ³n Final con Consenso]

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#9f9,stroke:#333,stroke-width:2px
```

## ğŸ“Š Modelos Utilizados

### 1. MPNET (all-mpnet-base-v2)
- **Dimensiones**: 768 (vs 384 del original)
- **Peso en ensemble**: 2.0
- **Ventajas**:
  - Mayor capacidad de representaciÃ³n semÃ¡ntica
  - Mejor rendimiento en similitud de textos
  - Pre-entrenado con corpus diverso

### 2. BioBERT
- **Modelo**: `pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb`
- **Peso en ensemble**: 1.5
- **Ventajas**:
  - Especializado en literatura biomÃ©dica
  - Pre-entrenado con 4.5B palabras de PubMed
  - ComprensiÃ³n superior de tÃ©rminos mÃ©dicos

### 3. MiniLM (all-MiniLM-L6-v2)
- **Dimensiones**: 384
- **Peso en ensemble**: 1.0
- **Ventajas**:
  - Modelo ligero y rÃ¡pido
  - Buena lÃ­nea base para comparaciÃ³n
  - Eficiente en recursos

## ğŸ”§ TÃ©cnicas de OptimizaciÃ³n

### 1. Procesamiento de Texto Ponderado

```python
PonderaciÃ³n de componentes:
- Abstract:     40%  # InformaciÃ³n mÃ¡s rica
- TÃ­tulo:       30%  # Tema principal
- MeSH terms:   20%  # Vocabulario controlado
- Keywords:     10%  # TÃ©rminos adicionales
```

### 2. NormalizaciÃ³n L2

Todos los embeddings son normalizados usando norma L2:
```python
embedding_normalized = embedding / ||embedding||â‚‚
```

**Beneficios**:
- Similitudes en rango [0, 1]
- ComparaciÃ³n mÃ¡s justa entre vectores
- Estabilidad numÃ©rica mejorada

### 3. MÃºltiples Representaciones por CategorÃ­a

Cada categorÃ­a (ODS, PRONACES, LÃ­nea) tiene 3 representaciones:
1. **DescripciÃ³n tÃ©cnica**: TÃ©rminos formales y cientÃ­ficos
2. **TÃ©rminos MeSH**: Vocabulario biomÃ©dico controlado
3. **Outcomes esperados**: Impactos y resultados

### 4. Boost EspecÃ­fico del Dominio

AplicaciÃ³n de incrementos basados en:
- Presencia de tÃ©rminos MeSH relevantes (+0.05)
- Keywords en tÃ­tulo (+0.03)
- TÃ©rminos biomÃ©dicos en abstract (+0.01)

### 5. ExpansiÃ³n de TÃ©rminos MeSH

```python
Ejemplo de expansiÃ³n:
"Diabetes" â†’ ["Diabetes Mellitus", "Type 2 Diabetes",
             "Diabetes Complications", "Diabetic Nephropathy"]
```

## ğŸ“ˆ Proceso de ClasificaciÃ³n

### Paso 1: PreparaciÃ³n de Datos
```python
1. Cargar publicaciÃ³n desde PubMed metadata
2. Extraer: tÃ­tulo, abstract, MeSH terms, keywords
3. Aplicar ponderaciÃ³n por componente
4. Concatenar texto procesado
```

### Paso 2: GeneraciÃ³n de Embeddings
```python
1. Generar embeddings con cada modelo
2. Aplicar normalizaciÃ³n L2
3. Calcular similitud de coseno
4. Aplicar boost de dominio
```

### Paso 3: Sistema de Ensemble
```python
1. Recopilar votos de cada modelo
2. Aplicar pesos del ensemble
3. Calcular consenso entre modelos
4. Determinar clasificaciÃ³n final
```

### Paso 4: AsignaciÃ³n de Confianza
```python
if consenso >= 75% and similitud >= 0.60:
    confianza = "alta"
elif consenso >= 50% and similitud >= 0.45:
    confianza = "media"
elif similitud >= 0.35:
    confianza = "baja"
else:
    confianza = "tentativa"
```

## ğŸ“Š Umbrales de ClasificaciÃ³n

### Umbrales Optimizados
| Tipo | Original | Optimizado | Mejora |
|------|----------|------------|--------|
| Principal | 0.45 | 0.50 | +11% |
| Secundario | 0.35 | 0.40 | +14% |
| MÃ­nimo | 0.30 | 0.35 | +17% |

### Niveles de Confianza
| Nivel | Rango de Similitud | Color |
|-------|-------------------|-------|
| Alta | > 60% | ğŸŸ¢ Verde |
| Media | 45% - 60% | ğŸŸ¡ Amarillo |
| Baja | 35% - 45% | ğŸŸ  Naranja |
| Tentativa | < 35% | ğŸ”´ Rojo |

## ğŸ“ˆ Resultados de la OptimizaciÃ³n

### ComparaciÃ³n Antes/DespuÃ©s

#### DistribuciÃ³n de Confianza
```
Original (MiniLM):
â”œâ”€ Tentativa: 84.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”œâ”€ Baja:       8.8% â–ˆâ–ˆ
â”œâ”€ Media:      6.6% â–ˆ
â””â”€ Alta:       0.0%

Optimizado (Ensemble):
â”œâ”€ Tentativa: 23.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”œâ”€ Baja:      37.6% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â”œâ”€ Media:     38.9% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â””â”€ Alta:       0.4% â–Œ
```

#### MÃ©tricas Clave
| MÃ©trica | Original | Optimizado | Mejora |
|---------|----------|------------|--------|
| Tentativas | 84.5% | 23.0% | **-61.5%** |
| Media/Alta | 6.6% | 39.3% | **+32.7%** |
| Similitud Promedio | 0.35 | 0.47 | **+34.2%** |
| Alto Consenso (>75%) | N/A | 52.7% | **Nuevo** |

## ğŸ”¬ ValidaciÃ³n y EvaluaciÃ³n

### MÃ©tricas de EvaluaciÃ³n
1. **PrecisiÃ³n de ClasificaciÃ³n**: RevisiÃ³n manual de muestra (n=30)
2. **Consistencia Inter-modelo**: Acuerdo entre clasificadores
3. **Cobertura TemÃ¡tica**: DistribuciÃ³n balanceada entre categorÃ­as
4. **Estabilidad Temporal**: Consistencia en re-ejecuciones

### Script de EvaluaciÃ³n
```bash
python src/classifiers/evaluate_embeddings.py
```

Genera reporte comparativo con:
- AnÃ¡lisis de confianza
- DistribuciÃ³n de similitudes
- Cambios por artÃ­culo
- MÃ©tricas de consenso

## ğŸ› ï¸ Uso del Sistema

### InstalaciÃ³n de Dependencias
```bash
pip install -r requirements-ml.txt
```

### EjecuciÃ³n de Clasificadores

#### OpciÃ³n 1: Sistema Completo (Recomendado)
```bash
# Ejecutar todos los clasificadores mejorados
python src/classifiers/ods_embeddings_classifier_enhanced.py
python src/classifiers/pronaces_embeddings_classifier_enhanced.py
python src/classifiers/embeddings_classifier_enhanced.py

# Ejecutar BioBERT
python src/classifiers/biobert_classifier.py

# Generar ensemble final
python src/classifiers/ensemble_classifier.py
```

#### OpciÃ³n 2: Clasificador Individual
```bash
# Solo ODS mejorado
python src/classifiers/ods_embeddings_classifier_enhanced.py
```

### Archivos de Salida
```
data/
â”œâ”€â”€ ods_classification_ensemble_final.json      # â­ USAR ESTE
â”œâ”€â”€ ods_classification_embeddings_enhanced.json # Individual MPNET
â”œâ”€â”€ ods_classification_biobert.json            # Individual BioBERT
â”œâ”€â”€ pronaces_classification_embeddings_enhanced.json
â””â”€â”€ lineas_classification/
    â””â”€â”€ embeddings_results_enhanced.json
```

## ğŸ”„ Mejoras Futuras

### Corto Plazo (1-2 semanas)
1. **Fine-tuning** con los 226 artÃ­culos etiquetados
2. **Active Learning** para casos de baja confianza
3. **Interfaz de retroalimentaciÃ³n** para correcciones manuales

### Mediano Plazo (1-2 meses)
1. **Cross-encoder** para re-ranking de resultados
2. **Graph embeddings** usando redes de citas
3. **Incorporar full-text** cuando estÃ© disponible

### Largo Plazo
1. **Modelo propio** entrenado especÃ­ficamente para DCNT
2. **Multi-modal** incorporando figuras y tablas
3. **Sistema de actualizaciÃ³n continua** con nuevas publicaciones

## ğŸ“š Referencias TÃ©cnicas

### Papers Relevantes
1. Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
2. Lee, J., et al. (2020). BioBERT: a pre-trained biomedical language representation model
3. Wang, W., et al. (2020). MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression

### Bibliotecas Utilizadas
- **sentence-transformers** v2.2.2
- **transformers** v4.36.2
- **scikit-learn** v1.3.2
- **torch** v2.0.0+

## ğŸ“§ Contacto y Soporte

Para preguntas sobre la metodologÃ­a o problemas tÃ©cnicos:
- **Desarrollador**: JosÃ© Gerardo Mora Almanza
- **Programa**: Doctorado en Ciencias de la NutriciÃ³n Traslacional
- **Universidad**: Universidad de Guadalajara

---

*Ãšltima actualizaciÃ³n: Octubre 2024*
*VersiÃ³n del sistema: 2.0 (Ensemble Optimizado)*